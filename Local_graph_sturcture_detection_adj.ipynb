{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c3d2e12-c131-4ed7-8fc0-4977fa60e7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dgl\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "# 其中包括激活函数, 损失函数, 池化函数 ,通过 F.xxx() 的形式，可以方便地调用 torch.nn.functional 模块中的各种函数\n",
    "import numpy\n",
    "import argparse\n",
    "import time\n",
    "from pygod.utils import load_data\n",
    "from dataset_process.local_graph_spectral import local_graph, neighbor_pad_or_truncate, gen_joint_structural_outlier\n",
    "from sklearn.metrics import f1_score, accuracy_score, recall_score, roc_auc_score, precision_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pygod.generator import gen_contextual_outlier, gen_structural_outlier\n",
    "\n",
    "from model.High_pass_GCN import *\n",
    "from sklearn.metrics import f1_score, accuracy_score, recall_score, roc_auc_score, precision_score, confusion_matrix\n",
    "from torch_geometric.utils import add_self_loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc9af476-0cb0-49e5-af87-b836a9a6b4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 初始化超参数\n",
    "parser = argparse.ArgumentParser(description='parameters')\n",
    "parser.add_argument('--dataset', type=str, default=\"weibo\") #\"weibo\"，\"inj_cora\"，\"enron\",\"disney\",\"books\",\"reddit\"\n",
    "#是否 normalize features\n",
    "parser.add_argument('--normalize_feat', type=bool, default=True)\n",
    "parser.add_argument('--calculate_contextual', type=bool, default=True)\n",
    "parser.add_argument('--contextual_n', type=int, default=434)\n",
    "parser.add_argument('--contextual_k', type=int, default=10)\n",
    "parser.add_argument('--calculate_structural', type=bool, default=True)\n",
    "parser.add_argument('--structural_n', type=int, default=434)\n",
    "parser.add_argument('--structural_m', type=int, default=10)\n",
    "parser.add_argument('--use_combine_outlier', type=bool, default=False)\n",
    "\n",
    "#contextual_n =183  #weibo: 434 # books 14 # cora: 70；dinesy: 3; reddit: 183; Enron: 3\n",
    "#contextual_k =30  #weibo: 10 # books 5 # Cora: 10；dinesy: 5; reddit: 30; Enron: 25\n",
    "#structural_n =183  #weibo: 434 # books 14 # Cora: 70；dinesy: 3; reddit: 183; Enron: 3,\n",
    "#structural_m =30  #weibo: 10 # books 5 # Cora: 10；dinesy: 5; reddit: 30; Enron: 25,\n",
    "\n",
    "#features dim: reddit: 64+32; disney:28+32; weibo: 400+32, enron: 18+32; books:21+32; inj_cora:1433+32  ;\n",
    "parser.add_argument(\"--hid_dim_c\", type=int, default= 64, help=\"Hidden layer dimension\") \n",
    "parser.add_argument(\"--hid_dim_s\", type=int, default=32, help=\"Hidden layer dimension\") \n",
    "parser.add_argument(\"--hid_dim_j\", type=int, default=32, help=\"Hidden layer dimension\") \n",
    "\n",
    "parser.add_argument(\"--train_ratio\", type=float, default=0.4, help=\"Training ratio\")\n",
    "parser.add_argument(\"--epoch\", type=int, default=500, help=\"The max number of epochs\") # For yelp，epoch =200; For amazon/tfinance/tsocial，epoch =100\n",
    "parser.add_argument(\"--run\", type=int, default=1, help=\"Running times\")\n",
    "parser.add_argument(\"--k_c\", type=int, default=2, help=\"k_c in ChebConv\")\n",
    "parser.add_argument(\"--k_s\", type=int, default=2, help=\"k_s in ChebConv\")\n",
    "parser.add_argument(\"--k_j\", type=int, default=2, help=\"k_j in ChebConv\")\n",
    "from torch_geometric.utils import to_scipy_sparse_matrix\n",
    "from scipy.sparse.linalg import eigs\n",
    "\n",
    "args = parser.parse_args(args = [])\n",
    "\n",
    "#2. 读取数据集\n",
    "dataset_str = args.dataset\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "data = load_data(dataset_str)\n",
    "\n",
    "# 计算最大特征值\n",
    "edge_index = data.edge_index\n",
    "num_nodes = data.num_nodes  # 如果需要提供节点数量\n",
    "edge_index_tensor = to_scipy_sparse_matrix(edge_index, num_nodes=num_nodes)\n",
    "#max_eigenvalue = eigs(edge_index_tensor, k=1, which='LR')[0][0].real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12209dd4-0606-4c9e-ab00-eb3411dfa3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. 节点特征归一化\n",
    "node_features = data.x \n",
    "if args.normalize_feat:\n",
    "    #特征归一化\n",
    "    node_features_min = node_features.min()\n",
    "    node_features_max = node_features.max()\n",
    "    node_features = (node_features - node_features_min)/node_features_max\n",
    "    data.x = node_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0622a8c-0632-4c7a-aafc-d51464eeb600",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yc: torch.Size([8405]) tensor(434)\n"
     ]
    }
   ],
   "source": [
    "#4.计算local graph features 并归一化\n",
    "# a.产生结构、属性和joint anomaly\n",
    "calculate_contextual=args.calculate_contextual\n",
    "calculate_structural=args.calculate_structural\n",
    "yc = []\n",
    "ys = []\n",
    "yj = []\n",
    "    \n",
    "if calculate_contextual:\n",
    "        \n",
    "    if dataset_str == \"inj_cora\":\n",
    "        yc = data.y >> 0 & 1 # contextual outliers\n",
    "    else:\n",
    "        data, yc = gen_contextual_outlier(data=data,n=args.contextual_n,k=args.contextual_k)\n",
    "            \n",
    "    yc = yc.cpu().detach()\n",
    "    print(\"Yc:\",yc.shape,sum(yc))\n",
    "    \n",
    "    \n",
    "if calculate_structural:\n",
    "        \n",
    "    if dataset_str == \"inj_cora\":\n",
    "        ys = data.y >> 1 & 1 # structural outliers\n",
    "    else:\n",
    "        data, ys = gen_structural_outlier(data=data,n=args.structural_n,m=args.structural_m,p=0.2)\n",
    "            \n",
    "    data, yj = gen_joint_structural_outlier(data=data,n=args.structural_n,m=args.structural_m)\n",
    "        \n",
    "    \n",
    "if args.use_combine_outlier:\n",
    "    data.y = torch.logical_or(ys, yc).int()\n",
    "        \n",
    "ysj = torch.logical_or(ys, yj).int()\n",
    "data.y = data.y.bool()    # binary labels (inlier/outlier)\n",
    "\n",
    "ys = ys.bool()\n",
    "yj = yj.bool()\n",
    "#添加自环\n",
    "data.edge_index, _ = add_self_loops(data.edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78fae023-9f8b-4a94-8e7a-a582d561608e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#b.计算 local grpah spectrum\n",
    "neighbor_dict, neighbor_num_list, neighbor_edge_spectral = local_graph (data, device)\n",
    "#c. local spectral 截取固定长度（32）长度不足补0\n",
    "k = 32  # 目标长度\n",
    "neighbor_edge_spectral_fixed = neighbor_pad_or_truncate(neighbor_edge_spectral, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06e66e8a-a521-4c71-87c8-6bfa4ec4477d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# d. 按键排序，形成local graph spectral 特征\n",
    "sorted_tensors = []\n",
    "for i in range(data.x.shape[0]):\n",
    "    if i in neighbor_edge_spectral_fixed.keys():\n",
    "        sorted_tensors.append(neighbor_edge_spectral_fixed[i])\n",
    "    else:\n",
    "        vector = torch.zeros(k)\n",
    "        sorted_tensors.append(vector)\n",
    "\n",
    "#sorted_tensors = [neighbor_edge_spectral_fixed[key] for key in sorted(neighbor_edge_spectral_fixed.keys())]\n",
    "\n",
    "# 将所有一维 Tensor 堆叠成一个二维 Tensor（每个一维 Tensor 作为一行）\n",
    "neighbor_spectral_features = torch.stack(sorted_tensors, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "07249021-cd55-4ac7-90cb-ec4eca107bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for Reddit\n",
    "# node_features:            torch.Size([10984, 64])\n",
    "# neighbor_spectral_tensor：torch.Size([10984, 32])\n",
    "#e. 归一化\n",
    "if args.normalize_feat:\n",
    "    #特征归一化\n",
    "    neighbor_spectral_features_min = neighbor_spectral_features.real.min()\n",
    "    neighbor_spectral_featuress_max = neighbor_spectral_features.real.max()\n",
    "    neighbor_spectral_features = (neighbor_spectral_features.real - neighbor_spectral_features_min)/neighbor_spectral_featuress_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f62e07bc-ed74-475b-adb8-f6681320e749",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model_c, model_s, model_j, data, neighbor_spectral_features, ys, yj, args):\n",
    "    # contextual_outlier\n",
    "    features_c = data.x\n",
    "    labels_c = data.y\n",
    "     # structural_outlier\n",
    "    features_s = neighbor_spectral_features\n",
    "    labels_s = ys\n",
    "     # jiont_outlier\n",
    "    features_j = neighbor_spectral_features\n",
    "    labels_j = yj\n",
    "    \n",
    "    index = list(range(len(labels_c)))\n",
    "\n",
    "    idx_train_c, idx_rest_c, y_train_c, y_rest_c = train_test_split(index, labels_c[index], stratify=labels_c[index],\n",
    "                                                            train_size=args.train_ratio,\n",
    "                                                            random_state=2, shuffle=True)\n",
    "    idx_valid_c, idx_test_c, y_valid_c, y_test_c = train_test_split(idx_rest_c, y_rest_c, stratify=y_rest_c,\n",
    "                                                            test_size=0.67,\n",
    "                                                            random_state=2, shuffle=True)\n",
    "    idx_train_s, idx_rest_s, y_train_s, y_rest_s = train_test_split(index, labels_s[index], stratify=labels_s[index],\n",
    "                                                            train_size=args.train_ratio,\n",
    "                                                            random_state=2, shuffle=True)\n",
    "    idx_valid_s, idx_test_s, y_valid_s, y_tes_s = train_test_split(idx_rest_s, y_rest_s, stratify=y_rest_s,\n",
    "                                                            test_size=0.67,\n",
    "                                                            random_state=2, shuffle=True)\n",
    "    idx_train_j, idx_rest_j, y_train_j, y_rest_j = train_test_split(index, labels_j[index], stratify=labels_j[index],\n",
    "                                                            train_size=args.train_ratio,\n",
    "                                                            random_state=2, shuffle=True)\n",
    "    idx_valid_j, idx_test_j, y_valid_j, y_tes_j = train_test_split(idx_rest_j, y_rest_j, stratify=y_rest_j,\n",
    "                                                            test_size=0.67,\n",
    "                                                            random_state=2, shuffle=True)\n",
    "    train_mask_c = torch.zeros([len(labels_c)]).bool()\n",
    "    val_mask_c = torch.zeros([len(labels_c)]).bool()\n",
    "    test_mask_c = torch.zeros([len(labels_c)]).bool()\n",
    "    train_mask_s = torch.zeros([len(labels_s)]).bool()\n",
    "    val_mask_s = torch.zeros([len(labels_s)]).bool()\n",
    "    test_mask_s = torch.zeros([len(labels_s)]).bool()\n",
    "    train_mask_j = torch.zeros([len(labels_j)]).bool()\n",
    "    val_mask_j = torch.zeros([len(labels_j)]).bool()\n",
    "    test_mask_j = torch.zeros([len(labels_j)]).bool()\n",
    "    print(\" y_train:\", y_train_c.shape, sum(y_train_c))\n",
    "    \n",
    "    train_mask_c[idx_train_c] = 1\n",
    "    val_mask_c[idx_valid_c] = 1\n",
    "    test_mask_c[idx_test_c] = 1\n",
    "    train_mask_s[idx_train_s] = 1\n",
    "    val_mask_s[idx_valid_s] = 1\n",
    "    test_mask_s[idx_test_s] = 1\n",
    "    train_mask_j[idx_train_j] = 1\n",
    "    val_mask_j[idx_valid_j] = 1\n",
    "    test_mask_j[idx_test_j] = 1\n",
    "    print('train/dev/test samples c: ', train_mask_c.sum().item(), val_mask_c.sum().item(), test_mask_c.sum().item())\n",
    "    print('train/dev/test samples  s: ', train_mask_s.sum().item(), val_mask_s.sum().item(), test_mask_s.sum().item())\n",
    "    print('train/dev/test samples  j: ', train_mask_j.sum().item(), val_mask_j.sum().item(), test_mask_j.sum().item())\n",
    "    \n",
    "    \n",
    "    optimizer_c = torch.optim.Adam(model_c.parameters(), lr=0.01)\n",
    "    optimizer_s = torch.optim.Adam(model_s.parameters(), lr=0.01)\n",
    "    optimizer_j = torch.optim.Adam(model_j.parameters(), lr=0.01)\n",
    "    \n",
    "    best_f1_c, final_tf1_c, final_trec_c, final_tpre_c, final_tmf1_c, final_tauc_c = 0., 0., 0., 0., 0., 0.\n",
    "    best_f1_s, final_tf1_s, final_trec_s, final_tpre_s, final_tmf1_s, final_tauc_s = 0., 0., 0., 0., 0., 0.\n",
    "    best_f1_j, final_tf1_j, final_trec_j, final_tpre_j, final_tmf1_j, final_tauc_j = 0., 0., 0., 0., 0., 0.\n",
    "\n",
    "\n",
    "    #对bool型的不允许“-”操作1-labels[train_mask] 改为：~labels[train_mask]\n",
    "    weight_c = (~labels_c[train_mask_c]).sum().item() / labels_c[train_mask_c].sum().item()\n",
    "    weight_s = (~labels_s[train_mask_s]).sum().item() / labels_s[train_mask_s].sum().item()\n",
    "    weight_j = (~labels_j[train_mask_j]).sum().item() / labels_j[train_mask_j].sum().item()\n",
    "    print('cross entropy weight: ', weight_c, weight_s, weight_j)\n",
    "    time_start = time.time()\n",
    "    for e in range(args.epoch):\n",
    "        # 训练\n",
    "        model_c.train()\n",
    "        model_s.train()\n",
    "        model_j.train()\n",
    "        \n",
    "        # 调用模型中的forward函数\n",
    "        logits_c = model_c(features_c,data)\n",
    "        logits_s = model_s(features_s,data)\n",
    "        logits_j = model_j(features_j,data)\n",
    "        \n",
    "        #labels[train_mask] 需要long型\n",
    "        loss_c = F.cross_entropy(logits_c[train_mask_c], labels_c[train_mask_c].to(torch.long), weight = torch.tensor([1., weight_c]))\n",
    "        loss_s = F.cross_entropy(logits_s[train_mask_s], labels_s[train_mask_s].to(torch.long), weight = torch.tensor([1., weight_s]))\n",
    "        loss_j = F.cross_entropy(logits_j[train_mask_j], labels_j[train_mask_j].to(torch.long), weight = torch.tensor([1., weight_j]))\n",
    "        \n",
    "        optimizer_c.zero_grad()\n",
    "        optimizer_s.zero_grad()\n",
    "        optimizer_j.zero_grad()\n",
    "        \n",
    "        loss_c.backward()\n",
    "        loss_s.backward()\n",
    "        loss_j.backward()\n",
    "        \n",
    "        optimizer_c.step()\n",
    "        optimizer_s.step()\n",
    "        optimizer_j.step()\n",
    "        \n",
    "        #验证\n",
    "        model_c.eval()\n",
    "        model_s.eval()\n",
    "        model_j.eval()\n",
    "        probs_c = logits_c.softmax(1)\n",
    "        probs_s = logits_s.softmax(1)\n",
    "        probs_j = logits_j.softmax(1)\n",
    "        \n",
    "        f1_c, thres_c = get_best_f1(labels_c[val_mask_c], probs_c[val_mask_c])\n",
    "        f1_s, thres_s = get_best_f1(labels_s[val_mask_s], probs_s[val_mask_s])\n",
    "        f1_j, thres_j = get_best_f1(labels_j[val_mask_j], probs_j[val_mask_j])\n",
    "        \n",
    "        preds_c = numpy.zeros_like(labels_c)\n",
    "        preds_c[probs_c[:, 1] > thres_c] = 1\n",
    "        preds_s = numpy.zeros_like(labels_s)\n",
    "        preds_s[probs_s[:, 1] > thres_s] = 1\n",
    "        preds_j = numpy.zeros_like(labels_j)\n",
    "        preds_j[probs_j[:, 1] > thres_j] = 1\n",
    "\n",
    "        trec_c = recall_score(labels_c[test_mask_c], preds_c[test_mask_c])\n",
    "        tpre_c = precision_score(labels_c[test_mask_c], preds_c[test_mask_c])\n",
    "        tmf1_c = f1_score(labels_c[test_mask_c], preds_c[test_mask_c], average='macro')\n",
    "        tauc_c = roc_auc_score(labels_c[test_mask_c], probs_c[test_mask_c][:, 1].detach().numpy())\n",
    "        \n",
    "        trec_s = recall_score(labels_s[test_mask_s], preds_s[test_mask_s])\n",
    "        tpre_s = precision_score(labels_s[test_mask_s], preds_s[test_mask_s])\n",
    "        tmf1_s = f1_score(labels_s[test_mask_s], preds_s[test_mask_s], average='macro')\n",
    "        tauc_s = roc_auc_score(labels_s[test_mask_s], probs_s[test_mask_s][:, 1].detach().numpy())\n",
    "\n",
    "        trec_j = recall_score(labels_j[test_mask_j], preds_j[test_mask_j])\n",
    "        tpre_j = precision_score(labels_j[test_mask_j], preds_j[test_mask_j])\n",
    "        tmf1_j = f1_score(labels_j[test_mask_j], preds_j[test_mask_j], average='macro')\n",
    "        tauc_j = roc_auc_score(labels_j[test_mask_j], probs_j[test_mask_j][:, 1].detach().numpy())\n",
    "\n",
    "        if best_f1_c < f1_c:\n",
    "            best_f1_c = f1_c\n",
    "            final_trec_c = trec_c\n",
    "            final_tpre_c = tpre_c\n",
    "            final_tmf1_c = tmf1_c\n",
    "            final_tauc_c = tauc_c\n",
    "        print('C: Epoch {}, loss: {:.4f}, val mf1: {:.4f}, (best {:.4f})'.format(e, loss_c, f1_c, best_f1_c))\n",
    "\n",
    "        if best_f1_s < f1_s:\n",
    "            best_f1_s = f1_s\n",
    "            final_trec_s = trec_s\n",
    "            final_tpre_s = tpre_s\n",
    "            final_tmf1_s = tmf1_s\n",
    "            final_tauc_s = tauc_s\n",
    "        print('s: Epoch {}, loss: {:.4f}, val mf1: {:.4f}, (best {:.4f})'.format(e, loss_s, f1_s, best_f1_s))\n",
    "\n",
    "        if best_f1_j < f1_j:\n",
    "            best_f1_j = f1_j\n",
    "            final_trec_j = trec_j\n",
    "            final_tpre_j = tpre_j\n",
    "            final_tmf1_j = tmf1_j\n",
    "            final_tauc_j = tauc_j\n",
    "        print('j: Epoch {}, loss: {:.4f}, val mf1: {:.4f}, (best {:.4f})'.format(e, loss_j, f1_j, best_f1_j))\n",
    "\n",
    "    time_end = time.time()\n",
    "    print('time cost: ', time_end - time_start, 's')\n",
    "    print('Test_c: REC {:.2f} PRE {:.2f} MF1 {:.2f} AUC {:.2f}'.format(final_trec_c*100,\n",
    "                                                                     final_tpre_c*100, final_tmf1_c*100, final_tauc_c*100))\n",
    "    print('Test_s: REC {:.2f} PRE {:.2f} MF1 {:.2f} AUC {:.2f}'.format(final_trec_s*100,\n",
    "                                                                     final_tpre_s*100, final_tmf1_s*100, final_tauc_s*100))\n",
    "    print('Test_j: REC {:.2f} PRE {:.2f} MF1 {:.2f} AUC {:.2f}'.format(final_trec_j*100,\n",
    "                                                                     final_tpre_j*100, final_tmf1_j*100, final_tauc_j*100))\n",
    "\n",
    "    return final_tmf1_c, final_tauc_c, final_tmf1_s, final_tauc_s, final_tmf1_j, final_tauc_j\n",
    "\n",
    "\n",
    "# threshold adjusting for best macro f1\n",
    "def get_best_f1(labels, probs):\n",
    "    best_f1, best_thre = 0, 0\n",
    "    for thres in np.linspace(0.05, 0.95, 19):\n",
    "        #构建一个与labels同维度的数组,并初始化所有变量为零\n",
    "        preds = np.zeros_like(labels)\n",
    "        preds[probs[:,1] > thres] = 1\n",
    "        #average='binary'：计算二分类问题中的 F1 分数（默认值）。\n",
    "        #average='micro'：对所有类别的真实和预测样本进行汇总，然后计算 F1 分数。\n",
    "        #average='macro'：计算每个类别的 F1 分数，然后取平均值。\n",
    "        #average=None：返回每个类别的 F1 分数。\n",
    "        # F1_score 详细原理间“备份”\n",
    "        mf1 = f1_score(labels, preds, average='macro')\n",
    "        if mf1 > best_f1:\n",
    "            best_f1 = mf1\n",
    "            best_thre = thres\n",
    "    return best_f1, best_thre\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f804113f-b380-42d4-bd15-6d33e826b136",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K.....: 2\n",
      "K.....: 2\n",
      "K.....: 2\n",
      " y_train: torch.Size([3362]) tensor(139)\n",
      "train/dev/test samples c:  3362 1664 3379\n",
      "train/dev/test samples  s:  3362 1664 3379\n",
      "train/dev/test samples  j:  3362 1664 3379\n",
      "cross entropy weight:  23.18705035971223 0.9366359447004609 18.32183908045977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C: Epoch 0, loss: 0.6935, val mf1: 0.4894, (best 0.4894)\n",
      "s: Epoch 0, loss: 0.6940, val mf1: 0.3701, (best 0.3701)\n",
      "j: Epoch 0, loss: 0.6943, val mf1: 0.5074, (best 0.5074)\n",
      "C: Epoch 1, loss: 0.7375, val mf1: 0.5204, (best 0.5204)\n",
      "s: Epoch 1, loss: 0.6892, val mf1: 0.4279, (best 0.4279)\n",
      "j: Epoch 1, loss: 0.6978, val mf1: 0.5095, (best 0.5095)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C: Epoch 2, loss: 0.8188, val mf1: 0.4894, (best 0.5204)\n",
      "s: Epoch 2, loss: 0.6854, val mf1: 0.5907, (best 0.5907)\n",
      "j: Epoch 2, loss: 0.6969, val mf1: 0.4867, (best 0.5095)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C: Epoch 3, loss: 0.6691, val mf1: 0.4894, (best 0.5204)\n",
      "s: Epoch 3, loss: 0.6772, val mf1: 0.5835, (best 0.5907)\n",
      "j: Epoch 3, loss: 0.6949, val mf1: 0.5020, (best 0.5095)\n",
      "C: Epoch 4, loss: 0.6792, val mf1: 0.5143, (best 0.5204)\n",
      "s: Epoch 4, loss: 0.6737, val mf1: 0.6095, (best 0.6095)\n",
      "j: Epoch 4, loss: 0.6923, val mf1: 0.4939, (best 0.5095)\n",
      "C: Epoch 5, loss: 0.6519, val mf1: 0.5204, (best 0.5204)\n",
      "s: Epoch 5, loss: 0.6658, val mf1: 0.6121, (best 0.6121)\n",
      "j: Epoch 5, loss: 0.6929, val mf1: 0.5040, (best 0.5095)\n",
      "C: Epoch 6, loss: 0.6540, val mf1: 0.5211, (best 0.5211)\n",
      "s: Epoch 6, loss: 0.6585, val mf1: 0.6382, (best 0.6382)\n",
      "j: Epoch 6, loss: 0.6930, val mf1: 0.5237, (best 0.5237)\n",
      "C: Epoch 7, loss: 0.6314, val mf1: 0.5457, (best 0.5457)\n",
      "s: Epoch 7, loss: 0.6525, val mf1: 0.6361, (best 0.6382)\n",
      "j: Epoch 7, loss: 0.6920, val mf1: 0.4953, (best 0.5237)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C: Epoch 8, loss: 0.6237, val mf1: 0.5476, (best 0.5476)\n",
      "s: Epoch 8, loss: 0.6441, val mf1: 0.6369, (best 0.6382)\n",
      "j: Epoch 8, loss: 0.6913, val mf1: 0.4867, (best 0.5237)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C: Epoch 9, loss: 0.6257, val mf1: 0.5125, (best 0.5476)\n",
      "s: Epoch 9, loss: 0.6382, val mf1: 0.6357, (best 0.6382)\n",
      "j: Epoch 9, loss: 0.6917, val mf1: 0.4867, (best 0.5237)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C: Epoch 10, loss: 0.6198, val mf1: 0.5230, (best 0.5476)\n",
      "s: Epoch 10, loss: 0.6309, val mf1: 0.6361, (best 0.6382)\n",
      "j: Epoch 10, loss: 0.6915, val mf1: 0.4867, (best 0.5237)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C: Epoch 11, loss: 0.6229, val mf1: 0.5549, (best 0.5549)\n",
      "s: Epoch 11, loss: 0.6239, val mf1: 0.6365, (best 0.6382)\n",
      "j: Epoch 11, loss: 0.6909, val mf1: 0.4867, (best 0.5237)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C: Epoch 12, loss: 0.6177, val mf1: 0.5561, (best 0.5561)\n",
      "s: Epoch 12, loss: 0.6179, val mf1: 0.6367, (best 0.6382)\n",
      "j: Epoch 12, loss: 0.6903, val mf1: 0.4867, (best 0.5237)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C: Epoch 13, loss: 0.6179, val mf1: 0.5305, (best 0.5561)\n",
      "s: Epoch 13, loss: 0.6104, val mf1: 0.6365, (best 0.6382)\n",
      "j: Epoch 13, loss: 0.6900, val mf1: 0.4867, (best 0.5237)\n",
      "C: Epoch 14, loss: 0.6164, val mf1: 0.5326, (best 0.5561)\n",
      "s: Epoch 14, loss: 0.6053, val mf1: 0.6382, (best 0.6382)\n",
      "j: Epoch 14, loss: 0.6897, val mf1: 0.5049, (best 0.5237)\n",
      "C: Epoch 15, loss: 0.6141, val mf1: 0.5709, (best 0.5709)\n",
      "s: Epoch 15, loss: 0.5983, val mf1: 0.6390, (best 0.6390)\n",
      "j: Epoch 15, loss: 0.6893, val mf1: 0.5022, (best 0.5237)\n",
      "C: Epoch 16, loss: 0.6167, val mf1: 0.5650, (best 0.5709)\n",
      "s: Epoch 16, loss: 0.5937, val mf1: 0.6365, (best 0.6390)\n",
      "j: Epoch 16, loss: 0.6885, val mf1: 0.5036, (best 0.5237)\n",
      "C: Epoch 17, loss: 0.6136, val mf1: 0.5578, (best 0.5709)\n",
      "s: Epoch 17, loss: 0.5874, val mf1: 0.6424, (best 0.6424)\n",
      "j: Epoch 17, loss: 0.6880, val mf1: 0.5042, (best 0.5237)\n",
      "C: Epoch 18, loss: 0.6143, val mf1: 0.5432, (best 0.5709)\n",
      "s: Epoch 18, loss: 0.5833, val mf1: 0.6386, (best 0.6424)\n",
      "j: Epoch 18, loss: 0.6875, val mf1: 0.5029, (best 0.5237)\n",
      "C: Epoch 19, loss: 0.6127, val mf1: 0.5387, (best 0.5709)\n",
      "s: Epoch 19, loss: 0.5780, val mf1: 0.6376, (best 0.6424)\n",
      "j: Epoch 19, loss: 0.6866, val mf1: 0.5019, (best 0.5237)\n",
      "C: Epoch 20, loss: 0.6115, val mf1: 0.5383, (best 0.5709)\n",
      "s: Epoch 20, loss: 0.5747, val mf1: 0.6496, (best 0.6496)\n",
      "j: Epoch 20, loss: 0.6856, val mf1: 0.4977, (best 0.5237)\n",
      "C: Epoch 21, loss: 0.6126, val mf1: 0.5379, (best 0.5709)\n",
      "s: Epoch 21, loss: 0.5712, val mf1: 0.6526, (best 0.6526)\n",
      "j: Epoch 21, loss: 0.6848, val mf1: 0.4959, (best 0.5237)\n",
      "C: Epoch 22, loss: 0.6105, val mf1: 0.5298, (best 0.5709)\n",
      "s: Epoch 22, loss: 0.5689, val mf1: 0.6421, (best 0.6526)\n",
      "j: Epoch 22, loss: 0.6835, val mf1: 0.4968, (best 0.5237)\n",
      "C: Epoch 23, loss: 0.6116, val mf1: 0.5341, (best 0.5709)\n",
      "s: Epoch 23, loss: 0.5655, val mf1: 0.6579, (best 0.6579)\n",
      "j: Epoch 23, loss: 0.6824, val mf1: 0.4953, (best 0.5237)\n",
      "C: Epoch 24, loss: 0.6111, val mf1: 0.5366, (best 0.5709)\n",
      "s: Epoch 24, loss: 0.5608, val mf1: 0.6546, (best 0.6579)\n",
      "j: Epoch 24, loss: 0.6811, val mf1: 0.5029, (best 0.5237)\n",
      "C: Epoch 25, loss: 0.6102, val mf1: 0.5481, (best 0.5709)\n",
      "s: Epoch 25, loss: 0.5612, val mf1: 0.6435, (best 0.6579)\n",
      "j: Epoch 25, loss: 0.6795, val mf1: 0.5023, (best 0.5237)\n",
      "C: Epoch 26, loss: 0.6108, val mf1: 0.5684, (best 0.5709)\n",
      "s: Epoch 26, loss: 0.5586, val mf1: 0.6586, (best 0.6586)\n",
      "j: Epoch 26, loss: 0.6778, val mf1: 0.5056, (best 0.5237)\n",
      "C: Epoch 27, loss: 0.6101, val mf1: 0.5481, (best 0.5709)\n",
      "s: Epoch 27, loss: 0.5549, val mf1: 0.6627, (best 0.6627)\n",
      "j: Epoch 27, loss: 0.6759, val mf1: 0.5051, (best 0.5237)\n",
      "C: Epoch 28, loss: 0.6091, val mf1: 0.5365, (best 0.5709)\n",
      "s: Epoch 28, loss: 0.5569, val mf1: 0.6436, (best 0.6627)\n",
      "j: Epoch 28, loss: 0.6740, val mf1: 0.4986, (best 0.5237)\n",
      "C: Epoch 29, loss: 0.6098, val mf1: 0.5343, (best 0.5709)\n",
      "s: Epoch 29, loss: 0.5508, val mf1: 0.6605, (best 0.6627)\n",
      "j: Epoch 29, loss: 0.6719, val mf1: 0.4971, (best 0.5237)\n",
      "C: Epoch 30, loss: 0.6086, val mf1: 0.5340, (best 0.5709)\n",
      "s: Epoch 30, loss: 0.5519, val mf1: 0.6586, (best 0.6627)\n",
      "j: Epoch 30, loss: 0.6701, val mf1: 0.4998, (best 0.5237)\n",
      "C: Epoch 31, loss: 0.6079, val mf1: 0.5324, (best 0.5709)\n",
      "s: Epoch 31, loss: 0.5479, val mf1: 0.6523, (best 0.6627)\n",
      "j: Epoch 31, loss: 0.6729, val mf1: 0.5014, (best 0.5237)\n",
      "C: Epoch 32, loss: 0.6074, val mf1: 0.5512, (best 0.5709)\n",
      "s: Epoch 32, loss: 0.5492, val mf1: 0.6509, (best 0.6627)\n",
      "j: Epoch 32, loss: 0.6770, val mf1: 0.5090, (best 0.5237)\n",
      "C: Epoch 33, loss: 0.6063, val mf1: 0.5381, (best 0.5709)\n",
      "s: Epoch 33, loss: 0.5462, val mf1: 0.6527, (best 0.6627)\n",
      "j: Epoch 33, loss: 0.6665, val mf1: 0.5238, (best 0.5238)\n",
      "C: Epoch 34, loss: 0.6060, val mf1: 0.5396, (best 0.5709)\n",
      "s: Epoch 34, loss: 0.5460, val mf1: 0.6602, (best 0.6627)\n",
      "j: Epoch 34, loss: 0.6727, val mf1: 0.5208, (best 0.5238)\n",
      "C: Epoch 35, loss: 0.6048, val mf1: 0.5388, (best 0.5709)\n",
      "s: Epoch 35, loss: 0.5446, val mf1: 0.6548, (best 0.6627)\n",
      "j: Epoch 35, loss: 0.6641, val mf1: 0.5173, (best 0.5238)\n",
      "C: Epoch 36, loss: 0.6036, val mf1: 0.5421, (best 0.5709)\n",
      "s: Epoch 36, loss: 0.5432, val mf1: 0.6555, (best 0.6627)\n",
      "j: Epoch 36, loss: 0.6701, val mf1: 0.5061, (best 0.5238)\n",
      "C: Epoch 37, loss: 0.6027, val mf1: 0.5452, (best 0.5709)\n",
      "s: Epoch 37, loss: 0.5433, val mf1: 0.6674, (best 0.6674)\n",
      "j: Epoch 37, loss: 0.6631, val mf1: 0.5030, (best 0.5238)\n",
      "C: Epoch 38, loss: 0.6021, val mf1: 0.5477, (best 0.5709)\n",
      "s: Epoch 38, loss: 0.5411, val mf1: 0.6567, (best 0.6674)\n",
      "j: Epoch 38, loss: 0.6666, val mf1: 0.5022, (best 0.5238)\n",
      "C: Epoch 39, loss: 0.6036, val mf1: 0.5699, (best 0.5709)\n",
      "s: Epoch 39, loss: 0.5419, val mf1: 0.6528, (best 0.6674)\n",
      "j: Epoch 39, loss: 0.6619, val mf1: 0.5214, (best 0.5238)\n",
      "C: Epoch 40, loss: 0.6041, val mf1: 0.5491, (best 0.5709)\n",
      "s: Epoch 40, loss: 0.5398, val mf1: 0.6612, (best 0.6674)\n",
      "j: Epoch 40, loss: 0.6645, val mf1: 0.5157, (best 0.5238)\n",
      "C: Epoch 41, loss: 0.6030, val mf1: 0.5660, (best 0.5709)\n",
      "s: Epoch 41, loss: 0.5391, val mf1: 0.6637, (best 0.6674)\n",
      "j: Epoch 41, loss: 0.6596, val mf1: 0.5076, (best 0.5238)\n",
      "C: Epoch 42, loss: 0.5979, val mf1: 0.5604, (best 0.5709)\n",
      "s: Epoch 42, loss: 0.5388, val mf1: 0.6598, (best 0.6674)\n",
      "j: Epoch 42, loss: 0.6628, val mf1: 0.5020, (best 0.5238)\n",
      "C: Epoch 43, loss: 0.6040, val mf1: 0.5517, (best 0.5709)\n",
      "s: Epoch 43, loss: 0.5367, val mf1: 0.6635, (best 0.6674)\n",
      "j: Epoch 43, loss: 0.6581, val mf1: 0.5101, (best 0.5238)\n",
      "C: Epoch 44, loss: 0.6016, val mf1: 0.5610, (best 0.5709)\n",
      "s: Epoch 44, loss: 0.5365, val mf1: 0.6639, (best 0.6674)\n",
      "j: Epoch 44, loss: 0.6606, val mf1: 0.5181, (best 0.5238)\n",
      "C: Epoch 45, loss: 0.5929, val mf1: 0.5584, (best 0.5709)\n",
      "s: Epoch 45, loss: 0.5354, val mf1: 0.6612, (best 0.6674)\n",
      "j: Epoch 45, loss: 0.6574, val mf1: 0.5099, (best 0.5238)\n",
      "C: Epoch 46, loss: 0.6006, val mf1: 0.5546, (best 0.5709)\n",
      "s: Epoch 46, loss: 0.5339, val mf1: 0.6626, (best 0.6674)\n",
      "j: Epoch 46, loss: 0.6581, val mf1: 0.5051, (best 0.5238)\n",
      "C: Epoch 47, loss: 0.5976, val mf1: 0.5446, (best 0.5709)\n",
      "s: Epoch 47, loss: 0.5334, val mf1: 0.6628, (best 0.6674)\n",
      "j: Epoch 47, loss: 0.6567, val mf1: 0.5098, (best 0.5238)\n",
      "C: Epoch 48, loss: 0.5941, val mf1: 0.5487, (best 0.5709)\n",
      "s: Epoch 48, loss: 0.5324, val mf1: 0.6687, (best 0.6687)\n",
      "j: Epoch 48, loss: 0.6558, val mf1: 0.5024, (best 0.5238)\n",
      "C: Epoch 49, loss: 0.5946, val mf1: 0.5584, (best 0.5709)\n",
      "s: Epoch 49, loss: 0.5310, val mf1: 0.6680, (best 0.6687)\n",
      "j: Epoch 49, loss: 0.6557, val mf1: 0.5121, (best 0.5238)\n",
      "C: Epoch 50, loss: 0.5877, val mf1: 0.5524, (best 0.5709)\n",
      "s: Epoch 50, loss: 0.5301, val mf1: 0.6678, (best 0.6687)\n",
      "j: Epoch 50, loss: 0.6539, val mf1: 0.5053, (best 0.5238)\n",
      "C: Epoch 51, loss: 0.5932, val mf1: 0.5573, (best 0.5709)\n",
      "s: Epoch 51, loss: 0.5293, val mf1: 0.6761, (best 0.6761)\n",
      "j: Epoch 51, loss: 0.6542, val mf1: 0.5030, (best 0.5238)\n",
      "C: Epoch 52, loss: 0.5898, val mf1: 0.5643, (best 0.5709)\n",
      "s: Epoch 52, loss: 0.5282, val mf1: 0.6710, (best 0.6761)\n",
      "j: Epoch 52, loss: 0.6523, val mf1: 0.5037, (best 0.5238)\n",
      "C: Epoch 53, loss: 0.5865, val mf1: 0.5583, (best 0.5709)\n",
      "s: Epoch 53, loss: 0.5269, val mf1: 0.6800, (best 0.6800)\n",
      "j: Epoch 53, loss: 0.6525, val mf1: 0.5034, (best 0.5238)\n",
      "C: Epoch 54, loss: 0.5902, val mf1: 0.5523, (best 0.5709)\n",
      "s: Epoch 54, loss: 0.5260, val mf1: 0.6802, (best 0.6802)\n",
      "j: Epoch 54, loss: 0.6510, val mf1: 0.5077, (best 0.5238)\n",
      "C: Epoch 55, loss: 0.5845, val mf1: 0.5542, (best 0.5709)\n",
      "s: Epoch 55, loss: 0.5254, val mf1: 0.6724, (best 0.6802)\n",
      "j: Epoch 55, loss: 0.6508, val mf1: 0.5023, (best 0.5238)\n",
      "C: Epoch 56, loss: 0.5871, val mf1: 0.5669, (best 0.5709)\n",
      "s: Epoch 56, loss: 0.5247, val mf1: 0.6887, (best 0.6887)\n",
      "j: Epoch 56, loss: 0.6501, val mf1: 0.4982, (best 0.5238)\n",
      "C: Epoch 57, loss: 0.5861, val mf1: 0.5504, (best 0.5709)\n",
      "s: Epoch 57, loss: 0.5239, val mf1: 0.6752, (best 0.6887)\n",
      "j: Epoch 57, loss: 0.6485, val mf1: 0.5022, (best 0.5238)\n",
      "C: Epoch 58, loss: 0.5837, val mf1: 0.5541, (best 0.5709)\n",
      "s: Epoch 58, loss: 0.5229, val mf1: 0.6875, (best 0.6887)\n",
      "j: Epoch 58, loss: 0.6488, val mf1: 0.5117, (best 0.5238)\n",
      "C: Epoch 59, loss: 0.5846, val mf1: 0.5630, (best 0.5709)\n",
      "s: Epoch 59, loss: 0.5219, val mf1: 0.6795, (best 0.6887)\n",
      "j: Epoch 59, loss: 0.6474, val mf1: 0.5084, (best 0.5238)\n",
      "C: Epoch 60, loss: 0.5833, val mf1: 0.5580, (best 0.5709)\n",
      "s: Epoch 60, loss: 0.5210, val mf1: 0.6848, (best 0.6887)\n",
      "j: Epoch 60, loss: 0.6462, val mf1: 0.5029, (best 0.5238)\n",
      "C: Epoch 61, loss: 0.5848, val mf1: 0.5580, (best 0.5709)\n",
      "s: Epoch 61, loss: 0.5201, val mf1: 0.6813, (best 0.6887)\n",
      "j: Epoch 61, loss: 0.6458, val mf1: 0.4943, (best 0.5238)\n",
      "C: Epoch 62, loss: 0.5816, val mf1: 0.5613, (best 0.5709)\n",
      "s: Epoch 62, loss: 0.5192, val mf1: 0.6782, (best 0.6887)\n",
      "j: Epoch 62, loss: 0.6455, val mf1: 0.5143, (best 0.5238)\n",
      "C: Epoch 63, loss: 0.5821, val mf1: 0.5599, (best 0.5709)\n",
      "s: Epoch 63, loss: 0.5183, val mf1: 0.6787, (best 0.6887)\n",
      "j: Epoch 63, loss: 0.6440, val mf1: 0.5019, (best 0.5238)\n",
      "C: Epoch 64, loss: 0.5820, val mf1: 0.5525, (best 0.5709)\n",
      "s: Epoch 64, loss: 0.5175, val mf1: 0.6814, (best 0.6887)\n",
      "j: Epoch 64, loss: 0.6434, val mf1: 0.4935, (best 0.5238)\n",
      "C: Epoch 65, loss: 0.5798, val mf1: 0.5576, (best 0.5709)\n",
      "s: Epoch 65, loss: 0.5168, val mf1: 0.6904, (best 0.6904)\n",
      "j: Epoch 65, loss: 0.6428, val mf1: 0.5036, (best 0.5238)\n",
      "C: Epoch 66, loss: 0.5800, val mf1: 0.5633, (best 0.5709)\n",
      "s: Epoch 66, loss: 0.5160, val mf1: 0.6840, (best 0.6904)\n",
      "j: Epoch 66, loss: 0.6427, val mf1: 0.5056, (best 0.5238)\n",
      "C: Epoch 67, loss: 0.5783, val mf1: 0.5609, (best 0.5709)\n",
      "s: Epoch 67, loss: 0.5153, val mf1: 0.6977, (best 0.6977)\n",
      "j: Epoch 67, loss: 0.6421, val mf1: 0.5020, (best 0.5238)\n",
      "C: Epoch 68, loss: 0.5787, val mf1: 0.5615, (best 0.5709)\n",
      "s: Epoch 68, loss: 0.5156, val mf1: 0.6875, (best 0.6977)\n",
      "j: Epoch 68, loss: 0.6414, val mf1: 0.4984, (best 0.5238)\n",
      "C: Epoch 69, loss: 0.5779, val mf1: 0.5621, (best 0.5709)\n",
      "s: Epoch 69, loss: 0.5172, val mf1: 0.6995, (best 0.6995)\n",
      "j: Epoch 69, loss: 0.6424, val mf1: 0.5133, (best 0.5238)\n",
      "C: Epoch 70, loss: 0.5767, val mf1: 0.5569, (best 0.5709)\n",
      "s: Epoch 70, loss: 0.5191, val mf1: 0.7012, (best 0.7012)\n",
      "j: Epoch 70, loss: 0.6403, val mf1: 0.5039, (best 0.5238)\n",
      "C: Epoch 71, loss: 0.5777, val mf1: 0.5540, (best 0.5709)\n",
      "s: Epoch 71, loss: 0.5138, val mf1: 0.6967, (best 0.7012)\n",
      "j: Epoch 71, loss: 0.6389, val mf1: 0.4993, (best 0.5238)\n",
      "C: Epoch 72, loss: 0.5773, val mf1: 0.5616, (best 0.5709)\n",
      "s: Epoch 72, loss: 0.5130, val mf1: 0.6875, (best 0.7012)\n",
      "j: Epoch 72, loss: 0.6378, val mf1: 0.4996, (best 0.5238)\n",
      "C: Epoch 73, loss: 0.5774, val mf1: 0.5558, (best 0.5709)\n",
      "s: Epoch 73, loss: 0.5147, val mf1: 0.6971, (best 0.7012)\n",
      "j: Epoch 73, loss: 0.6390, val mf1: 0.5002, (best 0.5238)\n",
      "C: Epoch 74, loss: 0.5800, val mf1: 0.5546, (best 0.5709)\n",
      "s: Epoch 74, loss: 0.5119, val mf1: 0.6975, (best 0.7012)\n",
      "j: Epoch 74, loss: 0.6392, val mf1: 0.4952, (best 0.5238)\n",
      "C: Epoch 75, loss: 0.5829, val mf1: 0.5596, (best 0.5709)\n",
      "s: Epoch 75, loss: 0.5101, val mf1: 0.6885, (best 0.7012)\n",
      "j: Epoch 75, loss: 0.6420, val mf1: 0.4940, (best 0.5238)\n",
      "C: Epoch 76, loss: 0.5812, val mf1: 0.5562, (best 0.5709)\n",
      "s: Epoch 76, loss: 0.5093, val mf1: 0.6919, (best 0.7012)\n",
      "j: Epoch 76, loss: 0.6567, val mf1: 0.5192, (best 0.5238)\n",
      "C: Epoch 77, loss: 0.5741, val mf1: 0.5594, (best 0.5709)\n",
      "s: Epoch 77, loss: 0.5100, val mf1: 0.6956, (best 0.7012)\n",
      "j: Epoch 77, loss: 0.6397, val mf1: 0.5063, (best 0.5238)\n",
      "C: Epoch 78, loss: 0.5747, val mf1: 0.5654, (best 0.5709)\n",
      "s: Epoch 78, loss: 0.5092, val mf1: 0.6875, (best 0.7012)\n",
      "j: Epoch 78, loss: 0.6480, val mf1: 0.4924, (best 0.5238)\n",
      "C: Epoch 79, loss: 0.5775, val mf1: 0.5536, (best 0.5709)\n",
      "s: Epoch 79, loss: 0.5066, val mf1: 0.6989, (best 0.7012)\n",
      "j: Epoch 79, loss: 0.6435, val mf1: 0.4987, (best 0.5238)\n",
      "C: Epoch 80, loss: 0.5751, val mf1: 0.5604, (best 0.5709)\n",
      "s: Epoch 80, loss: 0.5066, val mf1: 0.6989, (best 0.7012)\n",
      "j: Epoch 80, loss: 0.6408, val mf1: 0.5022, (best 0.5238)\n",
      "C: Epoch 81, loss: 0.5732, val mf1: 0.5547, (best 0.5709)\n",
      "s: Epoch 81, loss: 0.5074, val mf1: 0.6892, (best 0.7012)\n",
      "j: Epoch 81, loss: 0.6443, val mf1: 0.5180, (best 0.5238)\n",
      "C: Epoch 82, loss: 0.5712, val mf1: 0.5594, (best 0.5709)\n",
      "s: Epoch 82, loss: 0.5057, val mf1: 0.6976, (best 0.7012)\n",
      "j: Epoch 82, loss: 0.6369, val mf1: 0.4935, (best 0.5238)\n",
      "C: Epoch 83, loss: 0.5733, val mf1: 0.5583, (best 0.5709)\n",
      "s: Epoch 83, loss: 0.5047, val mf1: 0.6925, (best 0.7012)\n",
      "j: Epoch 83, loss: 0.6406, val mf1: 0.4875, (best 0.5238)\n",
      "C: Epoch 84, loss: 0.5763, val mf1: 0.5505, (best 0.5709)\n",
      "s: Epoch 84, loss: 0.5040, val mf1: 0.6910, (best 0.7012)\n",
      "j: Epoch 84, loss: 0.6351, val mf1: 0.4921, (best 0.5238)\n",
      "C: Epoch 85, loss: 0.5721, val mf1: 0.5574, (best 0.5709)\n",
      "s: Epoch 85, loss: 0.5036, val mf1: 0.6988, (best 0.7012)\n",
      "j: Epoch 85, loss: 0.6341, val mf1: 0.5000, (best 0.5238)\n",
      "C: Epoch 86, loss: 0.5694, val mf1: 0.5615, (best 0.5709)\n",
      "s: Epoch 86, loss: 0.5036, val mf1: 0.6921, (best 0.7012)\n",
      "j: Epoch 86, loss: 0.6363, val mf1: 0.5016, (best 0.5238)\n",
      "C: Epoch 87, loss: 0.5701, val mf1: 0.5590, (best 0.5709)\n",
      "s: Epoch 87, loss: 0.5019, val mf1: 0.6958, (best 0.7012)\n",
      "j: Epoch 87, loss: 0.6331, val mf1: 0.5032, (best 0.5238)\n",
      "C: Epoch 88, loss: 0.5707, val mf1: 0.5644, (best 0.5709)\n",
      "s: Epoch 88, loss: 0.5007, val mf1: 0.7018, (best 0.7018)\n",
      "j: Epoch 88, loss: 0.6327, val mf1: 0.4921, (best 0.5238)\n",
      "C: Epoch 89, loss: 0.5712, val mf1: 0.5586, (best 0.5709)\n",
      "s: Epoch 89, loss: 0.5007, val mf1: 0.6931, (best 0.7018)\n",
      "j: Epoch 89, loss: 0.6316, val mf1: 0.4937, (best 0.5238)\n",
      "C: Epoch 90, loss: 0.5702, val mf1: 0.5630, (best 0.5709)\n",
      "s: Epoch 90, loss: 0.5002, val mf1: 0.7048, (best 0.7048)\n",
      "j: Epoch 90, loss: 0.6298, val mf1: 0.4984, (best 0.5238)\n",
      "C: Epoch 91, loss: 0.5654, val mf1: 0.5572, (best 0.5709)\n",
      "s: Epoch 91, loss: 0.4988, val mf1: 0.6972, (best 0.7048)\n",
      "j: Epoch 91, loss: 0.6303, val mf1: 0.5098, (best 0.5238)\n",
      "C: Epoch 92, loss: 0.5664, val mf1: 0.5565, (best 0.5709)\n",
      "s: Epoch 92, loss: 0.4973, val mf1: 0.7012, (best 0.7048)\n",
      "j: Epoch 92, loss: 0.6292, val mf1: 0.4964, (best 0.5238)\n",
      "C: Epoch 93, loss: 0.5692, val mf1: 0.5577, (best 0.5709)\n",
      "s: Epoch 93, loss: 0.4967, val mf1: 0.7043, (best 0.7048)\n",
      "j: Epoch 93, loss: 0.6279, val mf1: 0.4952, (best 0.5238)\n",
      "C: Epoch 94, loss: 0.5763, val mf1: 0.5551, (best 0.5709)\n",
      "s: Epoch 94, loss: 0.4964, val mf1: 0.7021, (best 0.7048)\n",
      "j: Epoch 94, loss: 0.6285, val mf1: 0.5095, (best 0.5238)\n",
      "C: Epoch 95, loss: 0.6134, val mf1: 0.5579, (best 0.5709)\n",
      "s: Epoch 95, loss: 0.4951, val mf1: 0.7091, (best 0.7091)\n",
      "j: Epoch 95, loss: 0.6277, val mf1: 0.5009, (best 0.5238)\n",
      "C: Epoch 96, loss: 0.6206, val mf1: 0.5542, (best 0.5709)\n",
      "s: Epoch 96, loss: 0.4935, val mf1: 0.6996, (best 0.7091)\n",
      "j: Epoch 96, loss: 0.6293, val mf1: 0.5025, (best 0.5238)\n",
      "C: Epoch 97, loss: 0.6124, val mf1: 0.5615, (best 0.5709)\n",
      "s: Epoch 97, loss: 0.4920, val mf1: 0.7053, (best 0.7091)\n",
      "j: Epoch 97, loss: 0.6281, val mf1: 0.5056, (best 0.5238)\n",
      "C: Epoch 98, loss: 0.5797, val mf1: 0.5615, (best 0.5709)\n",
      "s: Epoch 98, loss: 0.4910, val mf1: 0.7103, (best 0.7103)\n",
      "j: Epoch 98, loss: 0.6275, val mf1: 0.5132, (best 0.5238)\n",
      "C: Epoch 99, loss: 0.5975, val mf1: 0.5714, (best 0.5714)\n",
      "s: Epoch 99, loss: 0.4904, val mf1: 0.7118, (best 0.7118)\n",
      "j: Epoch 99, loss: 0.6252, val mf1: 0.4996, (best 0.5238)\n",
      "C: Epoch 100, loss: 0.5955, val mf1: 0.5682, (best 0.5714)\n",
      "s: Epoch 100, loss: 0.4907, val mf1: 0.7149, (best 0.7149)\n",
      "j: Epoch 100, loss: 0.6240, val mf1: 0.4997, (best 0.5238)\n",
      "C: Epoch 101, loss: 0.5927, val mf1: 0.5561, (best 0.5714)\n",
      "s: Epoch 101, loss: 0.4927, val mf1: 0.7173, (best 0.7173)\n",
      "j: Epoch 101, loss: 0.6235, val mf1: 0.4990, (best 0.5238)\n",
      "C: Epoch 102, loss: 0.5843, val mf1: 0.5626, (best 0.5714)\n",
      "s: Epoch 102, loss: 0.4963, val mf1: 0.7245, (best 0.7245)\n",
      "j: Epoch 102, loss: 0.6218, val mf1: 0.5000, (best 0.5238)\n",
      "C: Epoch 103, loss: 0.5889, val mf1: 0.5555, (best 0.5714)\n",
      "s: Epoch 103, loss: 0.4891, val mf1: 0.7208, (best 0.7245)\n",
      "j: Epoch 103, loss: 0.6220, val mf1: 0.5010, (best 0.5238)\n",
      "C: Epoch 104, loss: 0.5804, val mf1: 0.5594, (best 0.5714)\n",
      "s: Epoch 104, loss: 0.4881, val mf1: 0.7104, (best 0.7245)\n",
      "j: Epoch 104, loss: 0.6213, val mf1: 0.5002, (best 0.5238)\n",
      "C: Epoch 105, loss: 0.5875, val mf1: 0.5591, (best 0.5714)\n",
      "s: Epoch 105, loss: 0.4894, val mf1: 0.7194, (best 0.7245)\n",
      "j: Epoch 105, loss: 0.6208, val mf1: 0.5022, (best 0.5238)\n",
      "C: Epoch 106, loss: 0.5721, val mf1: 0.5699, (best 0.5714)\n",
      "s: Epoch 106, loss: 0.4825, val mf1: 0.7219, (best 0.7245)\n",
      "j: Epoch 106, loss: 0.6208, val mf1: 0.4996, (best 0.5238)\n",
      "C: Epoch 107, loss: 0.5797, val mf1: 0.5725, (best 0.5725)\n",
      "s: Epoch 107, loss: 0.4886, val mf1: 0.7145, (best 0.7245)\n",
      "j: Epoch 107, loss: 0.6205, val mf1: 0.5018, (best 0.5238)\n",
      "C: Epoch 108, loss: 0.5813, val mf1: 0.5681, (best 0.5725)\n",
      "s: Epoch 108, loss: 0.4859, val mf1: 0.7231, (best 0.7245)\n",
      "j: Epoch 108, loss: 0.6218, val mf1: 0.5026, (best 0.5238)\n",
      "C: Epoch 109, loss: 0.5733, val mf1: 0.5578, (best 0.5725)\n",
      "s: Epoch 109, loss: 0.4802, val mf1: 0.7196, (best 0.7245)\n",
      "j: Epoch 109, loss: 0.6275, val mf1: 0.5100, (best 0.5238)\n",
      "C: Epoch 110, loss: 0.5771, val mf1: 0.5669, (best 0.5725)\n",
      "s: Epoch 110, loss: 0.4843, val mf1: 0.7246, (best 0.7246)\n",
      "j: Epoch 110, loss: 0.6312, val mf1: 0.5051, (best 0.5238)\n",
      "C: Epoch 111, loss: 0.5713, val mf1: 0.5601, (best 0.5725)\n",
      "s: Epoch 111, loss: 0.4772, val mf1: 0.7223, (best 0.7246)\n",
      "j: Epoch 111, loss: 0.6315, val mf1: 0.5080, (best 0.5238)\n",
      "C: Epoch 112, loss: 0.5760, val mf1: 0.5570, (best 0.5725)\n",
      "s: Epoch 112, loss: 0.4781, val mf1: 0.7244, (best 0.7246)\n",
      "j: Epoch 112, loss: 0.6173, val mf1: 0.5015, (best 0.5238)\n",
      "C: Epoch 113, loss: 0.5718, val mf1: 0.5669, (best 0.5725)\n",
      "s: Epoch 113, loss: 0.4770, val mf1: 0.7264, (best 0.7264)\n",
      "j: Epoch 113, loss: 0.6212, val mf1: 0.5012, (best 0.5238)\n",
      "C: Epoch 114, loss: 0.5713, val mf1: 0.5688, (best 0.5725)\n",
      "s: Epoch 114, loss: 0.4730, val mf1: 0.7254, (best 0.7264)\n",
      "j: Epoch 114, loss: 0.6279, val mf1: 0.5020, (best 0.5238)\n",
      "C: Epoch 115, loss: 0.5710, val mf1: 0.5715, (best 0.5725)\n",
      "s: Epoch 115, loss: 0.4745, val mf1: 0.7225, (best 0.7264)\n",
      "j: Epoch 115, loss: 0.6168, val mf1: 0.5049, (best 0.5238)\n",
      "C: Epoch 116, loss: 0.5669, val mf1: 0.5594, (best 0.5725)\n",
      "s: Epoch 116, loss: 0.4692, val mf1: 0.7289, (best 0.7289)\n",
      "j: Epoch 116, loss: 0.6186, val mf1: 0.4953, (best 0.5238)\n",
      "C: Epoch 117, loss: 0.5685, val mf1: 0.5796, (best 0.5796)\n",
      "s: Epoch 117, loss: 0.4707, val mf1: 0.7265, (best 0.7289)\n",
      "j: Epoch 117, loss: 0.6304, val mf1: 0.5028, (best 0.5238)\n",
      "C: Epoch 118, loss: 0.5662, val mf1: 0.5686, (best 0.5796)\n",
      "s: Epoch 118, loss: 0.4687, val mf1: 0.7258, (best 0.7289)\n",
      "j: Epoch 118, loss: 0.6160, val mf1: 0.4962, (best 0.5238)\n",
      "C: Epoch 119, loss: 0.5637, val mf1: 0.5731, (best 0.5796)\n",
      "s: Epoch 119, loss: 0.4668, val mf1: 0.7300, (best 0.7300)\n",
      "j: Epoch 119, loss: 0.6175, val mf1: 0.4984, (best 0.5238)\n",
      "C: Epoch 120, loss: 0.5651, val mf1: 0.5765, (best 0.5796)\n",
      "s: Epoch 120, loss: 0.4705, val mf1: 0.7284, (best 0.7300)\n",
      "j: Epoch 120, loss: 0.6291, val mf1: 0.4952, (best 0.5238)\n",
      "C: Epoch 121, loss: 0.5612, val mf1: 0.5707, (best 0.5796)\n",
      "s: Epoch 121, loss: 0.4740, val mf1: 0.7345, (best 0.7345)\n",
      "j: Epoch 121, loss: 0.6119, val mf1: 0.4968, (best 0.5238)\n",
      "C: Epoch 122, loss: 0.5614, val mf1: 0.5630, (best 0.5796)\n",
      "s: Epoch 122, loss: 0.4726, val mf1: 0.7268, (best 0.7345)\n",
      "j: Epoch 122, loss: 0.6237, val mf1: 0.4964, (best 0.5238)\n",
      "C: Epoch 123, loss: 0.5612, val mf1: 0.5604, (best 0.5796)\n",
      "s: Epoch 123, loss: 0.4606, val mf1: 0.7406, (best 0.7406)\n",
      "j: Epoch 123, loss: 0.6261, val mf1: 0.4999, (best 0.5238)\n",
      "C: Epoch 124, loss: 0.5592, val mf1: 0.5703, (best 0.5796)\n",
      "s: Epoch 124, loss: 0.4703, val mf1: 0.7329, (best 0.7406)\n",
      "j: Epoch 124, loss: 0.6133, val mf1: 0.4956, (best 0.5238)\n",
      "C: Epoch 125, loss: 0.5586, val mf1: 0.5718, (best 0.5796)\n",
      "s: Epoch 125, loss: 0.4671, val mf1: 0.7293, (best 0.7406)\n",
      "j: Epoch 125, loss: 0.6316, val mf1: 0.4959, (best 0.5238)\n",
      "C: Epoch 126, loss: 0.5570, val mf1: 0.5687, (best 0.5796)\n",
      "s: Epoch 126, loss: 0.4588, val mf1: 0.7353, (best 0.7406)\n",
      "j: Epoch 126, loss: 0.6124, val mf1: 0.4981, (best 0.5238)\n",
      "C: Epoch 127, loss: 0.5565, val mf1: 0.5617, (best 0.5796)\n",
      "s: Epoch 127, loss: 0.4704, val mf1: 0.7331, (best 0.7406)\n",
      "j: Epoch 127, loss: 0.6207, val mf1: 0.5022, (best 0.5238)\n",
      "C: Epoch 128, loss: 0.5548, val mf1: 0.5579, (best 0.5796)\n",
      "s: Epoch 128, loss: 0.4618, val mf1: 0.7346, (best 0.7406)\n",
      "j: Epoch 128, loss: 0.6125, val mf1: 0.5077, (best 0.5238)\n",
      "C: Epoch 129, loss: 0.5534, val mf1: 0.5606, (best 0.5796)\n",
      "s: Epoch 129, loss: 0.4638, val mf1: 0.7380, (best 0.7406)\n",
      "j: Epoch 129, loss: 0.6132, val mf1: 0.5032, (best 0.5238)\n",
      "C: Epoch 130, loss: 0.5521, val mf1: 0.5658, (best 0.5796)\n",
      "s: Epoch 130, loss: 0.4579, val mf1: 0.7380, (best 0.7406)\n",
      "j: Epoch 130, loss: 0.6156, val mf1: 0.5010, (best 0.5238)\n",
      "C: Epoch 131, loss: 0.5520, val mf1: 0.5640, (best 0.5796)\n",
      "s: Epoch 131, loss: 0.4571, val mf1: 0.7427, (best 0.7427)\n",
      "j: Epoch 131, loss: 0.6084, val mf1: 0.5001, (best 0.5238)\n",
      "C: Epoch 132, loss: 0.5571, val mf1: 0.5669, (best 0.5796)\n",
      "s: Epoch 132, loss: 0.4621, val mf1: 0.7357, (best 0.7427)\n",
      "j: Epoch 132, loss: 0.6185, val mf1: 0.5005, (best 0.5238)\n",
      "C: Epoch 133, loss: 0.6284, val mf1: 0.5724, (best 0.5796)\n",
      "s: Epoch 133, loss: 0.4506, val mf1: 0.7401, (best 0.7427)\n",
      "j: Epoch 133, loss: 0.6085, val mf1: 0.4932, (best 0.5238)\n",
      "C: Epoch 134, loss: 0.7589, val mf1: 0.5457, (best 0.5796)\n",
      "s: Epoch 134, loss: 0.4581, val mf1: 0.7413, (best 0.7427)\n",
      "j: Epoch 134, loss: 0.6105, val mf1: 0.5016, (best 0.5238)\n",
      "C: Epoch 135, loss: 0.6817, val mf1: 0.5379, (best 0.5796)\n",
      "s: Epoch 135, loss: 0.4577, val mf1: 0.7407, (best 0.7427)\n",
      "j: Epoch 135, loss: 0.6099, val mf1: 0.5012, (best 0.5238)\n",
      "C: Epoch 136, loss: 0.6363, val mf1: 0.5431, (best 0.5796)\n",
      "s: Epoch 136, loss: 0.4481, val mf1: 0.7461, (best 0.7461)\n",
      "j: Epoch 136, loss: 0.6053, val mf1: 0.4980, (best 0.5238)\n",
      "C: Epoch 137, loss: 0.6416, val mf1: 0.5608, (best 0.5796)\n",
      "s: Epoch 137, loss: 0.4581, val mf1: 0.7414, (best 0.7461)\n",
      "j: Epoch 137, loss: 0.6093, val mf1: 0.5009, (best 0.5238)\n",
      "C: Epoch 138, loss: 0.6463, val mf1: 0.5647, (best 0.5796)\n",
      "s: Epoch 138, loss: 0.4490, val mf1: 0.7526, (best 0.7526)\n",
      "j: Epoch 138, loss: 0.6032, val mf1: 0.5039, (best 0.5238)\n",
      "C: Epoch 139, loss: 0.6151, val mf1: 0.5867, (best 0.5867)\n",
      "s: Epoch 139, loss: 0.4501, val mf1: 0.7451, (best 0.7526)\n",
      "j: Epoch 139, loss: 0.6076, val mf1: 0.5006, (best 0.5238)\n",
      "C: Epoch 140, loss: 0.6185, val mf1: 0.5834, (best 0.5867)\n",
      "s: Epoch 140, loss: 0.4491, val mf1: 0.7458, (best 0.7526)\n",
      "j: Epoch 140, loss: 0.6043, val mf1: 0.5022, (best 0.5238)\n",
      "C: Epoch 141, loss: 0.6254, val mf1: 0.5624, (best 0.5867)\n",
      "s: Epoch 141, loss: 0.4432, val mf1: 0.7450, (best 0.7526)\n",
      "j: Epoch 141, loss: 0.6035, val mf1: 0.5019, (best 0.5238)\n",
      "C: Epoch 142, loss: 0.6219, val mf1: 0.5530, (best 0.5867)\n",
      "s: Epoch 142, loss: 0.4482, val mf1: 0.7490, (best 0.7526)\n",
      "j: Epoch 142, loss: 0.6037, val mf1: 0.5039, (best 0.5238)\n",
      "C: Epoch 143, loss: 0.6127, val mf1: 0.5583, (best 0.5867)\n",
      "s: Epoch 143, loss: 0.4402, val mf1: 0.7506, (best 0.7526)\n",
      "j: Epoch 143, loss: 0.6008, val mf1: 0.5042, (best 0.5238)\n",
      "C: Epoch 144, loss: 0.6073, val mf1: 0.5606, (best 0.5867)\n",
      "s: Epoch 144, loss: 0.4451, val mf1: 0.7451, (best 0.7526)\n",
      "j: Epoch 144, loss: 0.6026, val mf1: 0.5015, (best 0.5238)\n",
      "C: Epoch 145, loss: 0.6090, val mf1: 0.5575, (best 0.5867)\n",
      "s: Epoch 145, loss: 0.4412, val mf1: 0.7514, (best 0.7526)\n",
      "j: Epoch 145, loss: 0.5998, val mf1: 0.5039, (best 0.5238)\n",
      "C: Epoch 146, loss: 0.6123, val mf1: 0.5640, (best 0.5867)\n",
      "s: Epoch 146, loss: 0.4392, val mf1: 0.7575, (best 0.7575)\n",
      "j: Epoch 146, loss: 0.6009, val mf1: 0.4999, (best 0.5238)\n",
      "C: Epoch 147, loss: 0.6032, val mf1: 0.5584, (best 0.5867)\n",
      "s: Epoch 147, loss: 0.4429, val mf1: 0.7513, (best 0.7575)\n",
      "j: Epoch 147, loss: 0.6005, val mf1: 0.4956, (best 0.5238)\n",
      "C: Epoch 148, loss: 0.6011, val mf1: 0.5880, (best 0.5880)\n",
      "s: Epoch 148, loss: 0.4361, val mf1: 0.7577, (best 0.7577)\n",
      "j: Epoch 148, loss: 0.5981, val mf1: 0.4990, (best 0.5238)\n",
      "C: Epoch 149, loss: 0.6016, val mf1: 0.5799, (best 0.5880)\n",
      "s: Epoch 149, loss: 0.4387, val mf1: 0.7538, (best 0.7577)\n",
      "j: Epoch 149, loss: 0.5994, val mf1: 0.5016, (best 0.5238)\n",
      "C: Epoch 150, loss: 0.6003, val mf1: 0.5819, (best 0.5880)\n",
      "s: Epoch 150, loss: 0.4360, val mf1: 0.7562, (best 0.7577)\n",
      "j: Epoch 150, loss: 0.5972, val mf1: 0.4990, (best 0.5238)\n",
      "C: Epoch 151, loss: 0.5971, val mf1: 0.5891, (best 0.5891)\n",
      "s: Epoch 151, loss: 0.4333, val mf1: 0.7545, (best 0.7577)\n",
      "j: Epoch 151, loss: 0.5967, val mf1: 0.5063, (best 0.5238)\n",
      "C: Epoch 152, loss: 0.5947, val mf1: 0.5890, (best 0.5891)\n",
      "s: Epoch 152, loss: 0.4356, val mf1: 0.7533, (best 0.7577)\n",
      "j: Epoch 152, loss: 0.5971, val mf1: 0.5019, (best 0.5238)\n",
      "C: Epoch 153, loss: 0.5971, val mf1: 0.5865, (best 0.5891)\n",
      "s: Epoch 153, loss: 0.4324, val mf1: 0.7502, (best 0.7577)\n",
      "j: Epoch 153, loss: 0.5950, val mf1: 0.5059, (best 0.5238)\n",
      "C: Epoch 154, loss: 0.5939, val mf1: 0.5769, (best 0.5891)\n",
      "s: Epoch 154, loss: 0.4312, val mf1: 0.7562, (best 0.7577)\n",
      "j: Epoch 154, loss: 0.5947, val mf1: 0.5032, (best 0.5238)\n",
      "C: Epoch 155, loss: 0.5920, val mf1: 0.5661, (best 0.5891)\n",
      "s: Epoch 155, loss: 0.4323, val mf1: 0.7514, (best 0.7577)\n",
      "j: Epoch 155, loss: 0.5952, val mf1: 0.4985, (best 0.5238)\n",
      "C: Epoch 156, loss: 0.5918, val mf1: 0.5837, (best 0.5891)\n",
      "s: Epoch 156, loss: 0.4292, val mf1: 0.7548, (best 0.7577)\n",
      "j: Epoch 156, loss: 0.5933, val mf1: 0.5029, (best 0.5238)\n",
      "C: Epoch 157, loss: 0.5900, val mf1: 0.5829, (best 0.5891)\n",
      "s: Epoch 157, loss: 0.4278, val mf1: 0.7568, (best 0.7577)\n",
      "j: Epoch 157, loss: 0.5926, val mf1: 0.5042, (best 0.5238)\n",
      "C: Epoch 158, loss: 0.5870, val mf1: 0.5805, (best 0.5891)\n",
      "s: Epoch 158, loss: 0.4287, val mf1: 0.7544, (best 0.7577)\n",
      "j: Epoch 158, loss: 0.5927, val mf1: 0.5077, (best 0.5238)\n",
      "C: Epoch 159, loss: 0.5879, val mf1: 0.5788, (best 0.5891)\n",
      "s: Epoch 159, loss: 0.4271, val mf1: 0.7544, (best 0.7577)\n",
      "j: Epoch 159, loss: 0.5927, val mf1: 0.5053, (best 0.5238)\n",
      "C: Epoch 160, loss: 0.5875, val mf1: 0.5756, (best 0.5891)\n",
      "s: Epoch 160, loss: 0.4250, val mf1: 0.7551, (best 0.7577)\n",
      "j: Epoch 160, loss: 0.5910, val mf1: 0.5070, (best 0.5238)\n",
      "C: Epoch 161, loss: 0.5863, val mf1: 0.5684, (best 0.5891)\n",
      "s: Epoch 161, loss: 0.4250, val mf1: 0.7579, (best 0.7579)\n",
      "j: Epoch 161, loss: 0.5895, val mf1: 0.5088, (best 0.5238)\n",
      "C: Epoch 162, loss: 0.5872, val mf1: 0.5773, (best 0.5891)\n",
      "s: Epoch 162, loss: 0.4250, val mf1: 0.7586, (best 0.7586)\n",
      "j: Epoch 162, loss: 0.5900, val mf1: 0.5113, (best 0.5238)\n",
      "C: Epoch 163, loss: 0.5865, val mf1: 0.5838, (best 0.5891)\n",
      "s: Epoch 163, loss: 0.4235, val mf1: 0.7608, (best 0.7608)\n",
      "j: Epoch 163, loss: 0.5893, val mf1: 0.5091, (best 0.5238)\n",
      "C: Epoch 164, loss: 0.5858, val mf1: 0.5824, (best 0.5891)\n",
      "s: Epoch 164, loss: 0.4221, val mf1: 0.7576, (best 0.7608)\n",
      "j: Epoch 164, loss: 0.5882, val mf1: 0.5059, (best 0.5238)\n",
      "C: Epoch 165, loss: 0.5863, val mf1: 0.5817, (best 0.5891)\n",
      "s: Epoch 165, loss: 0.4226, val mf1: 0.7581, (best 0.7608)\n",
      "j: Epoch 165, loss: 0.5871, val mf1: 0.5106, (best 0.5238)\n",
      "C: Epoch 166, loss: 0.5854, val mf1: 0.5773, (best 0.5891)\n",
      "s: Epoch 166, loss: 0.4321, val mf1: 0.7609, (best 0.7609)\n",
      "j: Epoch 166, loss: 0.5865, val mf1: 0.5049, (best 0.5238)\n",
      "C: Epoch 167, loss: 0.5847, val mf1: 0.5806, (best 0.5891)\n",
      "s: Epoch 167, loss: 0.4272, val mf1: 0.7634, (best 0.7634)\n",
      "j: Epoch 167, loss: 0.5857, val mf1: 0.5056, (best 0.5238)\n",
      "C: Epoch 168, loss: 0.5845, val mf1: 0.5716, (best 0.5891)\n",
      "s: Epoch 168, loss: 0.4315, val mf1: 0.7557, (best 0.7634)\n",
      "j: Epoch 168, loss: 0.5852, val mf1: 0.5099, (best 0.5238)\n",
      "C: Epoch 169, loss: 0.5835, val mf1: 0.5730, (best 0.5891)\n",
      "s: Epoch 169, loss: 0.4436, val mf1: 0.7545, (best 0.7634)\n",
      "j: Epoch 169, loss: 0.5853, val mf1: 0.4998, (best 0.5238)\n",
      "C: Epoch 170, loss: 0.5837, val mf1: 0.5744, (best 0.5891)\n",
      "s: Epoch 170, loss: 0.4246, val mf1: 0.7625, (best 0.7634)\n",
      "j: Epoch 170, loss: 0.5844, val mf1: 0.5016, (best 0.5238)\n",
      "C: Epoch 171, loss: 0.5831, val mf1: 0.5733, (best 0.5891)\n",
      "s: Epoch 171, loss: 0.4224, val mf1: 0.7608, (best 0.7634)\n",
      "j: Epoch 171, loss: 0.5832, val mf1: 0.5036, (best 0.5238)\n",
      "C: Epoch 172, loss: 0.5830, val mf1: 0.5689, (best 0.5891)\n",
      "s: Epoch 172, loss: 0.4315, val mf1: 0.7623, (best 0.7634)\n",
      "j: Epoch 172, loss: 0.5822, val mf1: 0.5056, (best 0.5238)\n",
      "C: Epoch 173, loss: 0.5824, val mf1: 0.5665, (best 0.5891)\n",
      "s: Epoch 173, loss: 0.4179, val mf1: 0.7638, (best 0.7638)\n",
      "j: Epoch 173, loss: 0.5815, val mf1: 0.5053, (best 0.5238)\n",
      "C: Epoch 174, loss: 0.5818, val mf1: 0.5710, (best 0.5891)\n",
      "s: Epoch 174, loss: 0.4225, val mf1: 0.7581, (best 0.7638)\n",
      "j: Epoch 174, loss: 0.5805, val mf1: 0.5039, (best 0.5238)\n",
      "C: Epoch 175, loss: 0.5811, val mf1: 0.5737, (best 0.5891)\n",
      "s: Epoch 175, loss: 0.4239, val mf1: 0.7632, (best 0.7638)\n",
      "j: Epoch 175, loss: 0.5794, val mf1: 0.5056, (best 0.5238)\n",
      "C: Epoch 176, loss: 0.5812, val mf1: 0.5704, (best 0.5891)\n",
      "s: Epoch 176, loss: 0.4148, val mf1: 0.7642, (best 0.7642)\n",
      "j: Epoch 176, loss: 0.5786, val mf1: 0.5059, (best 0.5238)\n",
      "C: Epoch 177, loss: 0.5797, val mf1: 0.5661, (best 0.5891)\n",
      "s: Epoch 177, loss: 0.4268, val mf1: 0.7596, (best 0.7642)\n",
      "j: Epoch 177, loss: 0.5780, val mf1: 0.5009, (best 0.5238)\n",
      "C: Epoch 178, loss: 0.5796, val mf1: 0.5702, (best 0.5891)\n",
      "s: Epoch 178, loss: 0.4412, val mf1: 0.7620, (best 0.7642)\n",
      "j: Epoch 178, loss: 0.5774, val mf1: 0.5000, (best 0.5238)\n",
      "C: Epoch 179, loss: 0.5785, val mf1: 0.5631, (best 0.5891)\n",
      "s: Epoch 179, loss: 0.4245, val mf1: 0.7610, (best 0.7642)\n",
      "j: Epoch 179, loss: 0.5764, val mf1: 0.4986, (best 0.5238)\n",
      "C: Epoch 180, loss: 0.5781, val mf1: 0.5684, (best 0.5891)\n",
      "s: Epoch 180, loss: 0.4462, val mf1: 0.7455, (best 0.7642)\n",
      "j: Epoch 180, loss: 0.5762, val mf1: 0.5009, (best 0.5238)\n",
      "C: Epoch 181, loss: 0.5781, val mf1: 0.5766, (best 0.5891)\n",
      "s: Epoch 181, loss: 0.4239, val mf1: 0.7576, (best 0.7642)\n",
      "j: Epoch 181, loss: 0.5775, val mf1: 0.4999, (best 0.5238)\n",
      "C: Epoch 182, loss: 0.5773, val mf1: 0.5845, (best 0.5891)\n",
      "s: Epoch 182, loss: 0.4424, val mf1: 0.7598, (best 0.7642)\n",
      "j: Epoch 182, loss: 0.5810, val mf1: 0.4970, (best 0.5238)\n",
      "C: Epoch 183, loss: 0.5772, val mf1: 0.5771, (best 0.5891)\n",
      "s: Epoch 183, loss: 0.4357, val mf1: 0.7601, (best 0.7642)\n",
      "j: Epoch 183, loss: 0.5966, val mf1: 0.5059, (best 0.5238)\n",
      "C: Epoch 184, loss: 0.5766, val mf1: 0.5787, (best 0.5891)\n",
      "s: Epoch 184, loss: 0.4214, val mf1: 0.7594, (best 0.7642)\n",
      "j: Epoch 184, loss: 0.5935, val mf1: 0.5005, (best 0.5238)\n",
      "C: Epoch 185, loss: 0.5759, val mf1: 0.5771, (best 0.5891)\n",
      "s: Epoch 185, loss: 0.4338, val mf1: 0.7610, (best 0.7642)\n",
      "j: Epoch 185, loss: 0.5874, val mf1: 0.4946, (best 0.5238)\n",
      "C: Epoch 186, loss: 0.5759, val mf1: 0.5771, (best 0.5891)\n",
      "s: Epoch 186, loss: 0.4191, val mf1: 0.7600, (best 0.7642)\n",
      "j: Epoch 186, loss: 0.5744, val mf1: 0.4977, (best 0.5238)\n",
      "C: Epoch 187, loss: 0.5752, val mf1: 0.5787, (best 0.5891)\n",
      "s: Epoch 187, loss: 0.4249, val mf1: 0.7627, (best 0.7642)\n",
      "j: Epoch 187, loss: 0.5792, val mf1: 0.4911, (best 0.5238)\n",
      "C: Epoch 188, loss: 0.5750, val mf1: 0.5771, (best 0.5891)\n",
      "s: Epoch 188, loss: 0.4148, val mf1: 0.7645, (best 0.7645)\n",
      "j: Epoch 188, loss: 0.5927, val mf1: 0.4977, (best 0.5238)\n",
      "C: Epoch 189, loss: 0.5741, val mf1: 0.5703, (best 0.5891)\n",
      "s: Epoch 189, loss: 0.4254, val mf1: 0.7506, (best 0.7645)\n",
      "j: Epoch 189, loss: 0.5769, val mf1: 0.4974, (best 0.5238)\n",
      "C: Epoch 190, loss: 0.5738, val mf1: 0.5675, (best 0.5891)\n",
      "s: Epoch 190, loss: 0.4172, val mf1: 0.7600, (best 0.7645)\n",
      "j: Epoch 190, loss: 0.5724, val mf1: 0.5018, (best 0.5238)\n",
      "C: Epoch 191, loss: 0.5745, val mf1: 0.5785, (best 0.5891)\n",
      "s: Epoch 191, loss: 0.4206, val mf1: 0.7634, (best 0.7645)\n",
      "j: Epoch 191, loss: 0.5830, val mf1: 0.4955, (best 0.5238)\n",
      "C: Epoch 192, loss: 0.5729, val mf1: 0.5689, (best 0.5891)\n",
      "s: Epoch 192, loss: 0.4193, val mf1: 0.7628, (best 0.7645)\n",
      "j: Epoch 192, loss: 0.5777, val mf1: 0.4937, (best 0.5238)\n",
      "C: Epoch 193, loss: 0.5735, val mf1: 0.5601, (best 0.5891)\n",
      "s: Epoch 193, loss: 0.4138, val mf1: 0.7611, (best 0.7645)\n",
      "j: Epoch 193, loss: 0.5743, val mf1: 0.5058, (best 0.5238)\n",
      "C: Epoch 194, loss: 0.5723, val mf1: 0.5667, (best 0.5891)\n",
      "s: Epoch 194, loss: 0.4175, val mf1: 0.7546, (best 0.7645)\n",
      "j: Epoch 194, loss: 0.5711, val mf1: 0.4952, (best 0.5238)\n",
      "C: Epoch 195, loss: 0.5725, val mf1: 0.5703, (best 0.5891)\n",
      "s: Epoch 195, loss: 0.4122, val mf1: 0.7645, (best 0.7645)\n",
      "j: Epoch 195, loss: 0.5718, val mf1: 0.4965, (best 0.5238)\n",
      "C: Epoch 196, loss: 0.5713, val mf1: 0.5787, (best 0.5891)\n",
      "s: Epoch 196, loss: 0.4156, val mf1: 0.7600, (best 0.7645)\n",
      "j: Epoch 196, loss: 0.5746, val mf1: 0.5042, (best 0.5238)\n",
      "C: Epoch 197, loss: 0.5717, val mf1: 0.5645, (best 0.5891)\n",
      "s: Epoch 197, loss: 0.4109, val mf1: 0.7657, (best 0.7657)\n",
      "j: Epoch 197, loss: 0.5664, val mf1: 0.4958, (best 0.5238)\n",
      "C: Epoch 198, loss: 0.5722, val mf1: 0.5808, (best 0.5891)\n",
      "s: Epoch 198, loss: 0.4125, val mf1: 0.7627, (best 0.7657)\n",
      "j: Epoch 198, loss: 0.5699, val mf1: 0.4986, (best 0.5238)\n",
      "C: Epoch 199, loss: 0.5713, val mf1: 0.5782, (best 0.5891)\n",
      "s: Epoch 199, loss: 0.4081, val mf1: 0.7664, (best 0.7664)\n",
      "j: Epoch 199, loss: 0.5767, val mf1: 0.5063, (best 0.5238)\n",
      "C: Epoch 200, loss: 0.5703, val mf1: 0.5594, (best 0.5891)\n",
      "s: Epoch 200, loss: 0.4106, val mf1: 0.7632, (best 0.7664)\n",
      "j: Epoch 200, loss: 0.5677, val mf1: 0.5070, (best 0.5238)\n",
      "C: Epoch 201, loss: 0.5707, val mf1: 0.5604, (best 0.5891)\n",
      "s: Epoch 201, loss: 0.4076, val mf1: 0.7642, (best 0.7664)\n",
      "j: Epoch 201, loss: 0.5721, val mf1: 0.4940, (best 0.5238)\n",
      "C: Epoch 202, loss: 0.5698, val mf1: 0.5691, (best 0.5891)\n",
      "s: Epoch 202, loss: 0.4074, val mf1: 0.7600, (best 0.7664)\n",
      "j: Epoch 202, loss: 0.5692, val mf1: 0.5027, (best 0.5238)\n",
      "C: Epoch 203, loss: 0.5700, val mf1: 0.5777, (best 0.5891)\n",
      "s: Epoch 203, loss: 0.4050, val mf1: 0.7716, (best 0.7716)\n",
      "j: Epoch 203, loss: 0.5692, val mf1: 0.5015, (best 0.5238)\n",
      "C: Epoch 204, loss: 0.5695, val mf1: 0.5589, (best 0.5891)\n",
      "s: Epoch 204, loss: 0.4056, val mf1: 0.7666, (best 0.7716)\n",
      "j: Epoch 204, loss: 0.5656, val mf1: 0.5036, (best 0.5238)\n",
      "C: Epoch 205, loss: 0.5682, val mf1: 0.5627, (best 0.5891)\n",
      "s: Epoch 205, loss: 0.4042, val mf1: 0.7710, (best 0.7716)\n",
      "j: Epoch 205, loss: 0.5649, val mf1: 0.4971, (best 0.5238)\n",
      "C: Epoch 206, loss: 0.5684, val mf1: 0.5707, (best 0.5891)\n",
      "s: Epoch 206, loss: 0.4035, val mf1: 0.7616, (best 0.7716)\n",
      "j: Epoch 206, loss: 0.5681, val mf1: 0.5020, (best 0.5238)\n",
      "C: Epoch 207, loss: 0.5677, val mf1: 0.5694, (best 0.5891)\n",
      "s: Epoch 207, loss: 0.4020, val mf1: 0.7629, (best 0.7716)\n",
      "j: Epoch 207, loss: 0.5601, val mf1: 0.5007, (best 0.5238)\n",
      "C: Epoch 208, loss: 0.5676, val mf1: 0.5668, (best 0.5891)\n",
      "s: Epoch 208, loss: 0.4037, val mf1: 0.7656, (best 0.7716)\n",
      "j: Epoch 208, loss: 0.5621, val mf1: 0.4990, (best 0.5238)\n",
      "C: Epoch 209, loss: 0.5674, val mf1: 0.5702, (best 0.5891)\n",
      "s: Epoch 209, loss: 0.4035, val mf1: 0.7672, (best 0.7716)\n",
      "j: Epoch 209, loss: 0.5633, val mf1: 0.4985, (best 0.5238)\n",
      "C: Epoch 210, loss: 0.5677, val mf1: 0.5892, (best 0.5892)\n",
      "s: Epoch 210, loss: 0.4061, val mf1: 0.7581, (best 0.7716)\n",
      "j: Epoch 210, loss: 0.5597, val mf1: 0.5036, (best 0.5238)\n",
      "C: Epoch 211, loss: 0.5673, val mf1: 0.5616, (best 0.5892)\n",
      "s: Epoch 211, loss: 0.4102, val mf1: 0.7707, (best 0.7716)\n",
      "j: Epoch 211, loss: 0.5604, val mf1: 0.5056, (best 0.5238)\n",
      "C: Epoch 212, loss: 0.5674, val mf1: 0.5576, (best 0.5892)\n",
      "s: Epoch 212, loss: 0.4160, val mf1: 0.7601, (best 0.7716)\n",
      "j: Epoch 212, loss: 0.5565, val mf1: 0.5029, (best 0.5238)\n",
      "C: Epoch 213, loss: 0.5675, val mf1: 0.5689, (best 0.5892)\n",
      "s: Epoch 213, loss: 0.4145, val mf1: 0.7641, (best 0.7716)\n",
      "j: Epoch 213, loss: 0.5575, val mf1: 0.4955, (best 0.5238)\n",
      "C: Epoch 214, loss: 0.5698, val mf1: 0.5866, (best 0.5892)\n",
      "s: Epoch 214, loss: 0.4023, val mf1: 0.7637, (best 0.7716)\n",
      "j: Epoch 214, loss: 0.5570, val mf1: 0.5016, (best 0.5238)\n",
      "C: Epoch 215, loss: 0.5809, val mf1: 0.5715, (best 0.5892)\n",
      "s: Epoch 215, loss: 0.3991, val mf1: 0.7673, (best 0.7716)\n",
      "j: Epoch 215, loss: 0.5557, val mf1: 0.5091, (best 0.5238)\n",
      "C: Epoch 216, loss: 0.5888, val mf1: 0.5577, (best 0.5892)\n",
      "s: Epoch 216, loss: 0.4089, val mf1: 0.7646, (best 0.7716)\n",
      "j: Epoch 216, loss: 0.5557, val mf1: 0.5020, (best 0.5238)\n",
      "C: Epoch 217, loss: 0.5869, val mf1: 0.5800, (best 0.5892)\n",
      "s: Epoch 217, loss: 0.4049, val mf1: 0.7652, (best 0.7716)\n",
      "j: Epoch 217, loss: 0.5543, val mf1: 0.5012, (best 0.5238)\n",
      "C: Epoch 218, loss: 0.5673, val mf1: 0.5639, (best 0.5892)\n",
      "s: Epoch 218, loss: 0.3989, val mf1: 0.7737, (best 0.7737)\n",
      "j: Epoch 218, loss: 0.5539, val mf1: 0.5070, (best 0.5238)\n",
      "C: Epoch 219, loss: 0.5786, val mf1: 0.5615, (best 0.5892)\n",
      "s: Epoch 219, loss: 0.3974, val mf1: 0.7717, (best 0.7737)\n",
      "j: Epoch 219, loss: 0.5519, val mf1: 0.5033, (best 0.5238)\n",
      "C: Epoch 220, loss: 0.5690, val mf1: 0.5749, (best 0.5892)\n",
      "s: Epoch 220, loss: 0.4012, val mf1: 0.7637, (best 0.7737)\n",
      "j: Epoch 220, loss: 0.5516, val mf1: 0.4977, (best 0.5238)\n",
      "C: Epoch 221, loss: 0.5755, val mf1: 0.5713, (best 0.5892)\n",
      "s: Epoch 221, loss: 0.3989, val mf1: 0.7678, (best 0.7737)\n",
      "j: Epoch 221, loss: 0.5528, val mf1: 0.5006, (best 0.5238)\n",
      "C: Epoch 222, loss: 0.5685, val mf1: 0.5567, (best 0.5892)\n",
      "s: Epoch 222, loss: 0.3965, val mf1: 0.7698, (best 0.7737)\n",
      "j: Epoch 222, loss: 0.5517, val mf1: 0.5006, (best 0.5238)\n",
      "C: Epoch 223, loss: 0.5728, val mf1: 0.5588, (best 0.5892)\n",
      "s: Epoch 223, loss: 0.3969, val mf1: 0.7689, (best 0.7737)\n",
      "j: Epoch 223, loss: 0.5512, val mf1: 0.4958, (best 0.5238)\n",
      "C: Epoch 224, loss: 0.5681, val mf1: 0.5775, (best 0.5892)\n",
      "s: Epoch 224, loss: 0.4001, val mf1: 0.7681, (best 0.7737)\n",
      "j: Epoch 224, loss: 0.5499, val mf1: 0.5060, (best 0.5238)\n",
      "C: Epoch 225, loss: 0.5724, val mf1: 0.5742, (best 0.5892)\n",
      "s: Epoch 225, loss: 0.3959, val mf1: 0.7728, (best 0.7737)\n",
      "j: Epoch 225, loss: 0.5492, val mf1: 0.5103, (best 0.5238)\n",
      "C: Epoch 226, loss: 0.5683, val mf1: 0.5563, (best 0.5892)\n",
      "s: Epoch 226, loss: 0.3955, val mf1: 0.7726, (best 0.7737)\n",
      "j: Epoch 226, loss: 0.5478, val mf1: 0.4997, (best 0.5238)\n",
      "C: Epoch 227, loss: 0.5703, val mf1: 0.5550, (best 0.5892)\n",
      "s: Epoch 227, loss: 0.3961, val mf1: 0.7717, (best 0.7737)\n",
      "j: Epoch 227, loss: 0.5463, val mf1: 0.5036, (best 0.5238)\n",
      "C: Epoch 228, loss: 0.5674, val mf1: 0.5680, (best 0.5892)\n",
      "s: Epoch 228, loss: 0.3967, val mf1: 0.7702, (best 0.7737)\n",
      "j: Epoch 228, loss: 0.5463, val mf1: 0.5032, (best 0.5238)\n",
      "C: Epoch 229, loss: 0.5688, val mf1: 0.5681, (best 0.5892)\n",
      "s: Epoch 229, loss: 0.3936, val mf1: 0.7706, (best 0.7737)\n",
      "j: Epoch 229, loss: 0.5465, val mf1: 0.4989, (best 0.5238)\n",
      "C: Epoch 230, loss: 0.5668, val mf1: 0.5637, (best 0.5892)\n",
      "s: Epoch 230, loss: 0.3937, val mf1: 0.7743, (best 0.7743)\n",
      "j: Epoch 230, loss: 0.5494, val mf1: 0.4977, (best 0.5238)\n",
      "C: Epoch 231, loss: 0.5671, val mf1: 0.5755, (best 0.5892)\n",
      "s: Epoch 231, loss: 0.3936, val mf1: 0.7666, (best 0.7743)\n",
      "j: Epoch 231, loss: 0.5559, val mf1: 0.5102, (best 0.5238)\n",
      "C: Epoch 232, loss: 0.5672, val mf1: 0.5521, (best 0.5892)\n",
      "s: Epoch 232, loss: 0.3945, val mf1: 0.7703, (best 0.7743)\n",
      "j: Epoch 232, loss: 0.5534, val mf1: 0.5020, (best 0.5238)\n",
      "C: Epoch 233, loss: 0.5657, val mf1: 0.5561, (best 0.5892)\n",
      "s: Epoch 233, loss: 0.3930, val mf1: 0.7715, (best 0.7743)\n",
      "j: Epoch 233, loss: 0.5490, val mf1: 0.4995, (best 0.5238)\n",
      "C: Epoch 234, loss: 0.5662, val mf1: 0.5576, (best 0.5892)\n",
      "s: Epoch 234, loss: 0.3918, val mf1: 0.7718, (best 0.7743)\n",
      "j: Epoch 234, loss: 0.5431, val mf1: 0.5049, (best 0.5238)\n",
      "C: Epoch 235, loss: 0.5643, val mf1: 0.5703, (best 0.5892)\n",
      "s: Epoch 235, loss: 0.3913, val mf1: 0.7691, (best 0.7743)\n",
      "j: Epoch 235, loss: 0.5414, val mf1: 0.5020, (best 0.5238)\n",
      "C: Epoch 236, loss: 0.5657, val mf1: 0.5634, (best 0.5892)\n",
      "s: Epoch 236, loss: 0.3924, val mf1: 0.7650, (best 0.7743)\n",
      "j: Epoch 236, loss: 0.5440, val mf1: 0.5054, (best 0.5238)\n",
      "C: Epoch 237, loss: 0.5635, val mf1: 0.5615, (best 0.5892)\n",
      "s: Epoch 237, loss: 0.3936, val mf1: 0.7735, (best 0.7743)\n",
      "j: Epoch 237, loss: 0.5470, val mf1: 0.4991, (best 0.5238)\n",
      "C: Epoch 238, loss: 0.5639, val mf1: 0.5694, (best 0.5892)\n",
      "s: Epoch 238, loss: 0.3928, val mf1: 0.7693, (best 0.7743)\n",
      "j: Epoch 238, loss: 0.5516, val mf1: 0.5081, (best 0.5238)\n",
      "C: Epoch 239, loss: 0.5629, val mf1: 0.5748, (best 0.5892)\n",
      "s: Epoch 239, loss: 0.3925, val mf1: 0.7709, (best 0.7743)\n",
      "j: Epoch 239, loss: 0.5439, val mf1: 0.5022, (best 0.5238)\n",
      "C: Epoch 240, loss: 0.5627, val mf1: 0.5674, (best 0.5892)\n",
      "s: Epoch 240, loss: 0.3899, val mf1: 0.7739, (best 0.7743)\n",
      "j: Epoch 240, loss: 0.5387, val mf1: 0.4999, (best 0.5238)\n",
      "C: Epoch 241, loss: 0.5626, val mf1: 0.5692, (best 0.5892)\n",
      "s: Epoch 241, loss: 0.3894, val mf1: 0.7738, (best 0.7743)\n",
      "j: Epoch 241, loss: 0.5399, val mf1: 0.5036, (best 0.5238)\n",
      "C: Epoch 242, loss: 0.5615, val mf1: 0.5771, (best 0.5892)\n",
      "s: Epoch 242, loss: 0.3913, val mf1: 0.7712, (best 0.7743)\n",
      "j: Epoch 242, loss: 0.5448, val mf1: 0.5000, (best 0.5238)\n",
      "C: Epoch 243, loss: 0.5613, val mf1: 0.5710, (best 0.5892)\n",
      "s: Epoch 243, loss: 0.4014, val mf1: 0.7690, (best 0.7743)\n",
      "j: Epoch 243, loss: 0.5519, val mf1: 0.5036, (best 0.5238)\n",
      "C: Epoch 244, loss: 0.5611, val mf1: 0.5742, (best 0.5892)\n",
      "s: Epoch 244, loss: 0.3971, val mf1: 0.7697, (best 0.7743)\n",
      "j: Epoch 244, loss: 0.5439, val mf1: 0.5064, (best 0.5238)\n",
      "C: Epoch 245, loss: 0.5609, val mf1: 0.5677, (best 0.5892)\n",
      "s: Epoch 245, loss: 0.3975, val mf1: 0.7625, (best 0.7743)\n",
      "j: Epoch 245, loss: 0.5367, val mf1: 0.5042, (best 0.5238)\n",
      "C: Epoch 246, loss: 0.5596, val mf1: 0.5660, (best 0.5892)\n",
      "s: Epoch 246, loss: 0.3895, val mf1: 0.7684, (best 0.7743)\n",
      "j: Epoch 246, loss: 0.5377, val mf1: 0.5052, (best 0.5238)\n",
      "C: Epoch 247, loss: 0.5609, val mf1: 0.5763, (best 0.5892)\n",
      "s: Epoch 247, loss: 0.3952, val mf1: 0.7685, (best 0.7743)\n",
      "j: Epoch 247, loss: 0.5378, val mf1: 0.5026, (best 0.5238)\n",
      "C: Epoch 248, loss: 0.5592, val mf1: 0.5779, (best 0.5892)\n",
      "s: Epoch 248, loss: 0.3922, val mf1: 0.7681, (best 0.7743)\n",
      "j: Epoch 248, loss: 0.5398, val mf1: 0.4998, (best 0.5238)\n",
      "C: Epoch 249, loss: 0.5589, val mf1: 0.5686, (best 0.5892)\n",
      "s: Epoch 249, loss: 0.3956, val mf1: 0.7730, (best 0.7743)\n",
      "j: Epoch 249, loss: 0.5361, val mf1: 0.5030, (best 0.5238)\n",
      "C: Epoch 250, loss: 0.5585, val mf1: 0.5572, (best 0.5892)\n",
      "s: Epoch 250, loss: 0.3901, val mf1: 0.7652, (best 0.7743)\n",
      "j: Epoch 250, loss: 0.5330, val mf1: 0.5012, (best 0.5238)\n",
      "C: Epoch 251, loss: 0.5583, val mf1: 0.5650, (best 0.5892)\n",
      "s: Epoch 251, loss: 0.3923, val mf1: 0.7666, (best 0.7743)\n",
      "j: Epoch 251, loss: 0.5340, val mf1: 0.5012, (best 0.5238)\n",
      "C: Epoch 252, loss: 0.5587, val mf1: 0.5566, (best 0.5892)\n",
      "s: Epoch 252, loss: 0.3880, val mf1: 0.7675, (best 0.7743)\n",
      "j: Epoch 252, loss: 0.5339, val mf1: 0.5105, (best 0.5238)\n",
      "C: Epoch 253, loss: 0.5580, val mf1: 0.5556, (best 0.5892)\n",
      "s: Epoch 253, loss: 0.3906, val mf1: 0.7647, (best 0.7743)\n",
      "j: Epoch 253, loss: 0.5342, val mf1: 0.5096, (best 0.5238)\n",
      "C: Epoch 254, loss: 0.5577, val mf1: 0.5585, (best 0.5892)\n",
      "s: Epoch 254, loss: 0.3882, val mf1: 0.7739, (best 0.7743)\n",
      "j: Epoch 254, loss: 0.5324, val mf1: 0.5022, (best 0.5238)\n",
      "C: Epoch 255, loss: 0.5579, val mf1: 0.5715, (best 0.5892)\n",
      "s: Epoch 255, loss: 0.3911, val mf1: 0.7744, (best 0.7744)\n",
      "j: Epoch 255, loss: 0.5317, val mf1: 0.5023, (best 0.5238)\n",
      "C: Epoch 256, loss: 0.5583, val mf1: 0.5541, (best 0.5892)\n",
      "s: Epoch 256, loss: 0.3876, val mf1: 0.7706, (best 0.7744)\n",
      "j: Epoch 256, loss: 0.5318, val mf1: 0.5046, (best 0.5238)\n",
      "C: Epoch 257, loss: 0.5589, val mf1: 0.5753, (best 0.5892)\n",
      "s: Epoch 257, loss: 0.4437, val mf1: 0.7637, (best 0.7744)\n",
      "j: Epoch 257, loss: 0.5320, val mf1: 0.5050, (best 0.5238)\n",
      "C: Epoch 258, loss: 0.5587, val mf1: 0.5502, (best 0.5892)\n",
      "s: Epoch 258, loss: 0.4331, val mf1: 0.7647, (best 0.7744)\n",
      "j: Epoch 258, loss: 0.5296, val mf1: 0.5013, (best 0.5238)\n",
      "C: Epoch 259, loss: 0.5591, val mf1: 0.5622, (best 0.5892)\n",
      "s: Epoch 259, loss: 0.4696, val mf1: 0.7414, (best 0.7744)\n",
      "j: Epoch 259, loss: 0.5265, val mf1: 0.5088, (best 0.5238)\n",
      "C: Epoch 260, loss: 0.5622, val mf1: 0.5487, (best 0.5892)\n",
      "s: Epoch 260, loss: 0.4024, val mf1: 0.7703, (best 0.7744)\n",
      "j: Epoch 260, loss: 0.5267, val mf1: 0.5059, (best 0.5238)\n",
      "C: Epoch 261, loss: 0.5675, val mf1: 0.5566, (best 0.5892)\n",
      "s: Epoch 261, loss: 0.4270, val mf1: 0.7510, (best 0.7744)\n",
      "j: Epoch 261, loss: 0.5269, val mf1: 0.5042, (best 0.5238)\n",
      "C: Epoch 262, loss: 0.5657, val mf1: 0.5564, (best 0.5892)\n",
      "s: Epoch 262, loss: 0.4572, val mf1: 0.7601, (best 0.7744)\n",
      "j: Epoch 262, loss: 0.5279, val mf1: 0.5099, (best 0.5238)\n",
      "C: Epoch 263, loss: 0.5572, val mf1: 0.5662, (best 0.5892)\n",
      "s: Epoch 263, loss: 0.3953, val mf1: 0.7659, (best 0.7744)\n",
      "j: Epoch 263, loss: 0.5249, val mf1: 0.5071, (best 0.5238)\n",
      "C: Epoch 264, loss: 0.5665, val mf1: 0.5762, (best 0.5892)\n",
      "s: Epoch 264, loss: 0.4375, val mf1: 0.7563, (best 0.7744)\n",
      "j: Epoch 264, loss: 0.5242, val mf1: 0.5084, (best 0.5238)\n",
      "C: Epoch 265, loss: 0.5694, val mf1: 0.5536, (best 0.5892)\n",
      "s: Epoch 265, loss: 0.4396, val mf1: 0.7548, (best 0.7744)\n",
      "j: Epoch 265, loss: 0.5235, val mf1: 0.5068, (best 0.5238)\n",
      "C: Epoch 266, loss: 0.5872, val mf1: 0.5647, (best 0.5892)\n",
      "s: Epoch 266, loss: 0.4135, val mf1: 0.7657, (best 0.7744)\n",
      "j: Epoch 266, loss: 0.5246, val mf1: 0.5064, (best 0.5238)\n",
      "C: Epoch 267, loss: 0.5914, val mf1: 0.5587, (best 0.5892)\n",
      "s: Epoch 267, loss: 0.4272, val mf1: 0.7488, (best 0.7744)\n",
      "j: Epoch 267, loss: 0.5237, val mf1: 0.5051, (best 0.5238)\n",
      "C: Epoch 268, loss: 0.6416, val mf1: 0.5549, (best 0.5892)\n",
      "s: Epoch 268, loss: 0.4156, val mf1: 0.7641, (best 0.7744)\n",
      "j: Epoch 268, loss: 0.5228, val mf1: 0.5077, (best 0.5238)\n",
      "C: Epoch 269, loss: 0.5864, val mf1: 0.5734, (best 0.5892)\n",
      "s: Epoch 269, loss: 0.4138, val mf1: 0.7636, (best 0.7744)\n",
      "j: Epoch 269, loss: 0.5223, val mf1: 0.5107, (best 0.5238)\n",
      "C: Epoch 270, loss: 0.6120, val mf1: 0.5647, (best 0.5892)\n",
      "s: Epoch 270, loss: 0.4087, val mf1: 0.7546, (best 0.7744)\n",
      "j: Epoch 270, loss: 0.5228, val mf1: 0.5056, (best 0.5238)\n",
      "C: Epoch 271, loss: 0.5983, val mf1: 0.5531, (best 0.5892)\n",
      "s: Epoch 271, loss: 0.4101, val mf1: 0.7644, (best 0.7744)\n",
      "j: Epoch 271, loss: 0.5216, val mf1: 0.5056, (best 0.5238)\n",
      "C: Epoch 272, loss: 0.6124, val mf1: 0.5355, (best 0.5892)\n",
      "s: Epoch 272, loss: 0.4088, val mf1: 0.7663, (best 0.7744)\n",
      "j: Epoch 272, loss: 0.5206, val mf1: 0.5129, (best 0.5238)\n",
      "C: Epoch 273, loss: 0.5974, val mf1: 0.5415, (best 0.5892)\n",
      "s: Epoch 273, loss: 0.3985, val mf1: 0.7651, (best 0.7744)\n",
      "j: Epoch 273, loss: 0.5192, val mf1: 0.5118, (best 0.5238)\n",
      "C: Epoch 274, loss: 0.5934, val mf1: 0.5532, (best 0.5892)\n",
      "s: Epoch 274, loss: 0.4142, val mf1: 0.7567, (best 0.7744)\n",
      "j: Epoch 274, loss: 0.5179, val mf1: 0.5092, (best 0.5238)\n",
      "C: Epoch 275, loss: 0.5939, val mf1: 0.5675, (best 0.5892)\n",
      "s: Epoch 275, loss: 0.3986, val mf1: 0.7632, (best 0.7744)\n",
      "j: Epoch 275, loss: 0.5169, val mf1: 0.5059, (best 0.5238)\n",
      "C: Epoch 276, loss: 0.5926, val mf1: 0.5584, (best 0.5892)\n",
      "s: Epoch 276, loss: 0.3996, val mf1: 0.7709, (best 0.7744)\n",
      "j: Epoch 276, loss: 0.5165, val mf1: 0.5133, (best 0.5238)\n",
      "C: Epoch 277, loss: 0.5925, val mf1: 0.5701, (best 0.5892)\n",
      "s: Epoch 277, loss: 0.4015, val mf1: 0.7600, (best 0.7744)\n",
      "j: Epoch 277, loss: 0.5160, val mf1: 0.5170, (best 0.5238)\n",
      "C: Epoch 278, loss: 0.5930, val mf1: 0.5465, (best 0.5892)\n",
      "s: Epoch 278, loss: 0.4028, val mf1: 0.7575, (best 0.7744)\n",
      "j: Epoch 278, loss: 0.5191, val mf1: 0.5053, (best 0.5238)\n",
      "C: Epoch 279, loss: 0.5944, val mf1: 0.5551, (best 0.5892)\n",
      "s: Epoch 279, loss: 0.3951, val mf1: 0.7683, (best 0.7744)\n",
      "j: Epoch 279, loss: 0.5248, val mf1: 0.5068, (best 0.5238)\n",
      "C: Epoch 280, loss: 0.5904, val mf1: 0.5573, (best 0.5892)\n",
      "s: Epoch 280, loss: 0.3949, val mf1: 0.7651, (best 0.7744)\n",
      "j: Epoch 280, loss: 0.5270, val mf1: 0.5017, (best 0.5238)\n",
      "C: Epoch 281, loss: 0.5890, val mf1: 0.5648, (best 0.5892)\n",
      "s: Epoch 281, loss: 0.3989, val mf1: 0.7626, (best 0.7744)\n",
      "j: Epoch 281, loss: 0.5303, val mf1: 0.5102, (best 0.5238)\n",
      "C: Epoch 282, loss: 0.5903, val mf1: 0.5599, (best 0.5892)\n",
      "s: Epoch 282, loss: 0.3926, val mf1: 0.7630, (best 0.7744)\n",
      "j: Epoch 282, loss: 0.5306, val mf1: 0.5192, (best 0.5238)\n",
      "C: Epoch 283, loss: 0.5876, val mf1: 0.5608, (best 0.5892)\n",
      "s: Epoch 283, loss: 0.3945, val mf1: 0.7708, (best 0.7744)\n",
      "j: Epoch 283, loss: 0.5343, val mf1: 0.4993, (best 0.5238)\n",
      "C: Epoch 284, loss: 0.5860, val mf1: 0.5681, (best 0.5892)\n",
      "s: Epoch 284, loss: 0.3915, val mf1: 0.7649, (best 0.7744)\n",
      "j: Epoch 284, loss: 0.5261, val mf1: 0.5153, (best 0.5238)\n",
      "C: Epoch 285, loss: 0.5877, val mf1: 0.5582, (best 0.5892)\n",
      "s: Epoch 285, loss: 0.3923, val mf1: 0.7702, (best 0.7744)\n",
      "j: Epoch 285, loss: 0.5165, val mf1: 0.5004, (best 0.5238)\n",
      "C: Epoch 286, loss: 0.5867, val mf1: 0.5757, (best 0.5892)\n",
      "s: Epoch 286, loss: 0.3922, val mf1: 0.7680, (best 0.7744)\n",
      "j: Epoch 286, loss: 0.5178, val mf1: 0.4995, (best 0.5238)\n",
      "C: Epoch 287, loss: 0.5849, val mf1: 0.5730, (best 0.5892)\n",
      "s: Epoch 287, loss: 0.3904, val mf1: 0.7680, (best 0.7744)\n",
      "j: Epoch 287, loss: 0.5245, val mf1: 0.5094, (best 0.5238)\n",
      "C: Epoch 288, loss: 0.5823, val mf1: 0.5758, (best 0.5892)\n",
      "s: Epoch 288, loss: 0.3901, val mf1: 0.7657, (best 0.7744)\n",
      "j: Epoch 288, loss: 0.5241, val mf1: 0.5012, (best 0.5238)\n",
      "C: Epoch 289, loss: 0.5815, val mf1: 0.5689, (best 0.5892)\n",
      "s: Epoch 289, loss: 0.3883, val mf1: 0.7756, (best 0.7756)\n",
      "j: Epoch 289, loss: 0.5167, val mf1: 0.5090, (best 0.5238)\n",
      "C: Epoch 290, loss: 0.5808, val mf1: 0.5643, (best 0.5892)\n",
      "s: Epoch 290, loss: 0.3897, val mf1: 0.7733, (best 0.7756)\n",
      "j: Epoch 290, loss: 0.5148, val mf1: 0.5079, (best 0.5238)\n",
      "C: Epoch 291, loss: 0.5806, val mf1: 0.5711, (best 0.5892)\n",
      "s: Epoch 291, loss: 0.3874, val mf1: 0.7691, (best 0.7756)\n",
      "j: Epoch 291, loss: 0.5165, val mf1: 0.5062, (best 0.5238)\n",
      "C: Epoch 292, loss: 0.5801, val mf1: 0.5802, (best 0.5892)\n",
      "s: Epoch 292, loss: 0.3867, val mf1: 0.7736, (best 0.7756)\n",
      "j: Epoch 292, loss: 0.5125, val mf1: 0.5126, (best 0.5238)\n",
      "C: Epoch 293, loss: 0.5786, val mf1: 0.5699, (best 0.5892)\n",
      "s: Epoch 293, loss: 0.3871, val mf1: 0.7759, (best 0.7759)\n",
      "j: Epoch 293, loss: 0.5100, val mf1: 0.5149, (best 0.5238)\n",
      "C: Epoch 294, loss: 0.5788, val mf1: 0.5751, (best 0.5892)\n",
      "s: Epoch 294, loss: 0.3855, val mf1: 0.7731, (best 0.7759)\n",
      "j: Epoch 294, loss: 0.5111, val mf1: 0.5059, (best 0.5238)\n",
      "C: Epoch 295, loss: 0.5769, val mf1: 0.5724, (best 0.5892)\n",
      "s: Epoch 295, loss: 0.3860, val mf1: 0.7649, (best 0.7759)\n",
      "j: Epoch 295, loss: 0.5123, val mf1: 0.5105, (best 0.5238)\n",
      "C: Epoch 296, loss: 0.5789, val mf1: 0.5866, (best 0.5892)\n",
      "s: Epoch 296, loss: 0.3846, val mf1: 0.7788, (best 0.7788)\n",
      "j: Epoch 296, loss: 0.5060, val mf1: 0.5179, (best 0.5238)\n",
      "C: Epoch 297, loss: 0.5766, val mf1: 0.5847, (best 0.5892)\n",
      "s: Epoch 297, loss: 0.3843, val mf1: 0.7769, (best 0.7788)\n",
      "j: Epoch 297, loss: 0.5076, val mf1: 0.5121, (best 0.5238)\n",
      "C: Epoch 298, loss: 0.5781, val mf1: 0.5750, (best 0.5892)\n",
      "s: Epoch 298, loss: 0.3847, val mf1: 0.7725, (best 0.7788)\n",
      "j: Epoch 298, loss: 0.5088, val mf1: 0.5101, (best 0.5238)\n",
      "C: Epoch 299, loss: 0.5745, val mf1: 0.5616, (best 0.5892)\n",
      "s: Epoch 299, loss: 0.3834, val mf1: 0.7700, (best 0.7788)\n",
      "j: Epoch 299, loss: 0.5056, val mf1: 0.5012, (best 0.5238)\n",
      "C: Epoch 300, loss: 0.5756, val mf1: 0.5654, (best 0.5892)\n",
      "s: Epoch 300, loss: 0.3831, val mf1: 0.7691, (best 0.7788)\n",
      "j: Epoch 300, loss: 0.5063, val mf1: 0.5062, (best 0.5238)\n",
      "C: Epoch 301, loss: 0.5748, val mf1: 0.5647, (best 0.5892)\n",
      "s: Epoch 301, loss: 0.3832, val mf1: 0.7668, (best 0.7788)\n",
      "j: Epoch 301, loss: 0.5098, val mf1: 0.5041, (best 0.5238)\n",
      "C: Epoch 302, loss: 0.5751, val mf1: 0.5646, (best 0.5892)\n",
      "s: Epoch 302, loss: 0.3823, val mf1: 0.7737, (best 0.7788)\n",
      "j: Epoch 302, loss: 0.5089, val mf1: 0.5060, (best 0.5238)\n",
      "C: Epoch 303, loss: 0.5746, val mf1: 0.5627, (best 0.5892)\n",
      "s: Epoch 303, loss: 0.3821, val mf1: 0.7734, (best 0.7788)\n",
      "j: Epoch 303, loss: 0.5050, val mf1: 0.5077, (best 0.5238)\n",
      "C: Epoch 304, loss: 0.5734, val mf1: 0.5701, (best 0.5892)\n",
      "s: Epoch 304, loss: 0.3818, val mf1: 0.7691, (best 0.7788)\n",
      "j: Epoch 304, loss: 0.5047, val mf1: 0.5084, (best 0.5238)\n",
      "C: Epoch 305, loss: 0.5730, val mf1: 0.5639, (best 0.5892)\n",
      "s: Epoch 305, loss: 0.3812, val mf1: 0.7686, (best 0.7788)\n",
      "j: Epoch 305, loss: 0.5020, val mf1: 0.5026, (best 0.5238)\n",
      "C: Epoch 306, loss: 0.5718, val mf1: 0.5723, (best 0.5892)\n",
      "s: Epoch 306, loss: 0.3812, val mf1: 0.7724, (best 0.7788)\n",
      "j: Epoch 306, loss: 0.5021, val mf1: 0.5133, (best 0.5238)\n",
      "C: Epoch 307, loss: 0.5721, val mf1: 0.5691, (best 0.5892)\n",
      "s: Epoch 307, loss: 0.3807, val mf1: 0.7708, (best 0.7788)\n",
      "j: Epoch 307, loss: 0.4998, val mf1: 0.5094, (best 0.5238)\n",
      "C: Epoch 308, loss: 0.5715, val mf1: 0.5740, (best 0.5892)\n",
      "s: Epoch 308, loss: 0.3802, val mf1: 0.7690, (best 0.7788)\n",
      "j: Epoch 308, loss: 0.4994, val mf1: 0.5076, (best 0.5238)\n",
      "C: Epoch 309, loss: 0.5711, val mf1: 0.5675, (best 0.5892)\n",
      "s: Epoch 309, loss: 0.3803, val mf1: 0.7703, (best 0.7788)\n",
      "j: Epoch 309, loss: 0.4994, val mf1: 0.5046, (best 0.5238)\n",
      "C: Epoch 310, loss: 0.5713, val mf1: 0.5660, (best 0.5892)\n",
      "s: Epoch 310, loss: 0.3798, val mf1: 0.7710, (best 0.7788)\n",
      "j: Epoch 310, loss: 0.4996, val mf1: 0.5122, (best 0.5238)\n",
      "C: Epoch 311, loss: 0.5711, val mf1: 0.5672, (best 0.5892)\n",
      "s: Epoch 311, loss: 0.3794, val mf1: 0.7696, (best 0.7788)\n",
      "j: Epoch 311, loss: 0.4983, val mf1: 0.5098, (best 0.5238)\n",
      "C: Epoch 312, loss: 0.5696, val mf1: 0.5577, (best 0.5892)\n",
      "s: Epoch 312, loss: 0.3793, val mf1: 0.7724, (best 0.7788)\n",
      "j: Epoch 312, loss: 0.4968, val mf1: 0.5106, (best 0.5238)\n",
      "C: Epoch 313, loss: 0.5698, val mf1: 0.5661, (best 0.5892)\n",
      "s: Epoch 313, loss: 0.3789, val mf1: 0.7708, (best 0.7788)\n",
      "j: Epoch 313, loss: 0.4989, val mf1: 0.5118, (best 0.5238)\n",
      "C: Epoch 314, loss: 0.5702, val mf1: 0.5632, (best 0.5892)\n",
      "s: Epoch 314, loss: 0.3786, val mf1: 0.7702, (best 0.7788)\n",
      "j: Epoch 314, loss: 0.4956, val mf1: 0.5171, (best 0.5238)\n",
      "C: Epoch 315, loss: 0.5699, val mf1: 0.5577, (best 0.5892)\n",
      "s: Epoch 315, loss: 0.3785, val mf1: 0.7737, (best 0.7788)\n",
      "j: Epoch 315, loss: 0.4964, val mf1: 0.5141, (best 0.5238)\n",
      "C: Epoch 316, loss: 0.5693, val mf1: 0.5534, (best 0.5892)\n",
      "s: Epoch 316, loss: 0.3782, val mf1: 0.7714, (best 0.7788)\n",
      "j: Epoch 316, loss: 0.4968, val mf1: 0.5029, (best 0.5238)\n",
      "C: Epoch 317, loss: 0.5686, val mf1: 0.5585, (best 0.5892)\n",
      "s: Epoch 317, loss: 0.3779, val mf1: 0.7726, (best 0.7788)\n",
      "j: Epoch 317, loss: 0.5003, val mf1: 0.5075, (best 0.5238)\n",
      "C: Epoch 318, loss: 0.5686, val mf1: 0.5630, (best 0.5892)\n",
      "s: Epoch 318, loss: 0.3777, val mf1: 0.7714, (best 0.7788)\n",
      "j: Epoch 318, loss: 0.5033, val mf1: 0.5010, (best 0.5238)\n",
      "C: Epoch 319, loss: 0.5696, val mf1: 0.5682, (best 0.5892)\n",
      "s: Epoch 319, loss: 0.3774, val mf1: 0.7692, (best 0.7788)\n",
      "j: Epoch 319, loss: 0.5090, val mf1: 0.5083, (best 0.5238)\n",
      "C: Epoch 320, loss: 0.5681, val mf1: 0.5596, (best 0.5892)\n",
      "s: Epoch 320, loss: 0.3771, val mf1: 0.7709, (best 0.7788)\n",
      "j: Epoch 320, loss: 0.5070, val mf1: 0.5094, (best 0.5238)\n",
      "C: Epoch 321, loss: 0.5687, val mf1: 0.5549, (best 0.5892)\n",
      "s: Epoch 321, loss: 0.3770, val mf1: 0.7732, (best 0.7788)\n",
      "j: Epoch 321, loss: 0.5036, val mf1: 0.5029, (best 0.5238)\n",
      "C: Epoch 322, loss: 0.5697, val mf1: 0.5734, (best 0.5892)\n",
      "s: Epoch 322, loss: 0.3767, val mf1: 0.7688, (best 0.7788)\n",
      "j: Epoch 322, loss: 0.4977, val mf1: 0.5060, (best 0.5238)\n",
      "C: Epoch 323, loss: 0.5708, val mf1: 0.5640, (best 0.5892)\n",
      "s: Epoch 323, loss: 0.3764, val mf1: 0.7708, (best 0.7788)\n",
      "j: Epoch 323, loss: 0.4952, val mf1: 0.5192, (best 0.5238)\n",
      "C: Epoch 324, loss: 0.5698, val mf1: 0.5617, (best 0.5892)\n",
      "s: Epoch 324, loss: 0.3762, val mf1: 0.7749, (best 0.7788)\n",
      "j: Epoch 324, loss: 0.5017, val mf1: 0.5053, (best 0.5238)\n",
      "C: Epoch 325, loss: 0.5670, val mf1: 0.5603, (best 0.5892)\n",
      "s: Epoch 325, loss: 0.3761, val mf1: 0.7717, (best 0.7788)\n",
      "j: Epoch 325, loss: 0.4937, val mf1: 0.5077, (best 0.5238)\n",
      "C: Epoch 326, loss: 0.5685, val mf1: 0.5588, (best 0.5892)\n",
      "s: Epoch 326, loss: 0.3758, val mf1: 0.7726, (best 0.7788)\n",
      "j: Epoch 326, loss: 0.4944, val mf1: 0.5024, (best 0.5238)\n",
      "C: Epoch 327, loss: 0.5676, val mf1: 0.5699, (best 0.5892)\n",
      "s: Epoch 327, loss: 0.3755, val mf1: 0.7732, (best 0.7788)\n",
      "j: Epoch 327, loss: 0.5000, val mf1: 0.5020, (best 0.5238)\n",
      "C: Epoch 328, loss: 0.5666, val mf1: 0.5855, (best 0.5892)\n",
      "s: Epoch 328, loss: 0.3754, val mf1: 0.7735, (best 0.7788)\n",
      "j: Epoch 328, loss: 0.5216, val mf1: 0.5202, (best 0.5238)\n",
      "C: Epoch 329, loss: 0.5664, val mf1: 0.5561, (best 0.5892)\n",
      "s: Epoch 329, loss: 0.3752, val mf1: 0.7732, (best 0.7788)\n",
      "j: Epoch 329, loss: 0.5106, val mf1: 0.5118, (best 0.5238)\n",
      "C: Epoch 330, loss: 0.5661, val mf1: 0.5732, (best 0.5892)\n",
      "s: Epoch 330, loss: 0.3750, val mf1: 0.7718, (best 0.7788)\n",
      "j: Epoch 330, loss: 0.5047, val mf1: 0.5088, (best 0.5238)\n",
      "C: Epoch 331, loss: 0.5667, val mf1: 0.5649, (best 0.5892)\n",
      "s: Epoch 331, loss: 0.3747, val mf1: 0.7744, (best 0.7788)\n",
      "j: Epoch 331, loss: 0.5057, val mf1: 0.5275, (best 0.5275)\n",
      "C: Epoch 332, loss: 0.5649, val mf1: 0.5675, (best 0.5892)\n",
      "s: Epoch 332, loss: 0.3746, val mf1: 0.7780, (best 0.7788)\n",
      "j: Epoch 332, loss: 0.5041, val mf1: 0.5031, (best 0.5275)\n",
      "C: Epoch 333, loss: 0.5650, val mf1: 0.5713, (best 0.5892)\n",
      "s: Epoch 333, loss: 0.3743, val mf1: 0.7729, (best 0.7788)\n",
      "j: Epoch 333, loss: 0.5020, val mf1: 0.5004, (best 0.5275)\n",
      "C: Epoch 334, loss: 0.5637, val mf1: 0.5708, (best 0.5892)\n",
      "s: Epoch 334, loss: 0.3742, val mf1: 0.7738, (best 0.7788)\n",
      "j: Epoch 334, loss: 0.4999, val mf1: 0.5102, (best 0.5275)\n",
      "C: Epoch 335, loss: 0.5638, val mf1: 0.5587, (best 0.5892)\n",
      "s: Epoch 335, loss: 0.3740, val mf1: 0.7741, (best 0.7788)\n",
      "j: Epoch 335, loss: 0.4960, val mf1: 0.5008, (best 0.5275)\n",
      "C: Epoch 336, loss: 0.5644, val mf1: 0.5713, (best 0.5892)\n",
      "s: Epoch 336, loss: 0.3737, val mf1: 0.7738, (best 0.7788)\n",
      "j: Epoch 336, loss: 0.4940, val mf1: 0.5046, (best 0.5275)\n",
      "C: Epoch 337, loss: 0.5631, val mf1: 0.5699, (best 0.5892)\n",
      "s: Epoch 337, loss: 0.3736, val mf1: 0.7750, (best 0.7788)\n",
      "j: Epoch 337, loss: 0.4934, val mf1: 0.5075, (best 0.5275)\n",
      "C: Epoch 338, loss: 0.5626, val mf1: 0.5621, (best 0.5892)\n",
      "s: Epoch 338, loss: 0.3734, val mf1: 0.7733, (best 0.7788)\n",
      "j: Epoch 338, loss: 0.4921, val mf1: 0.5095, (best 0.5275)\n",
      "C: Epoch 339, loss: 0.5628, val mf1: 0.5627, (best 0.5892)\n",
      "s: Epoch 339, loss: 0.3733, val mf1: 0.7744, (best 0.7788)\n",
      "j: Epoch 339, loss: 0.4930, val mf1: 0.4965, (best 0.5275)\n",
      "C: Epoch 340, loss: 0.5625, val mf1: 0.5710, (best 0.5892)\n",
      "s: Epoch 340, loss: 0.3730, val mf1: 0.7720, (best 0.7788)\n",
      "j: Epoch 340, loss: 0.4933, val mf1: 0.5006, (best 0.5275)\n",
      "C: Epoch 341, loss: 0.5624, val mf1: 0.5640, (best 0.5892)\n",
      "s: Epoch 341, loss: 0.3728, val mf1: 0.7720, (best 0.7788)\n",
      "j: Epoch 341, loss: 0.4880, val mf1: 0.5021, (best 0.5275)\n",
      "C: Epoch 342, loss: 0.5614, val mf1: 0.5564, (best 0.5892)\n",
      "s: Epoch 342, loss: 0.3726, val mf1: 0.7762, (best 0.7788)\n",
      "j: Epoch 342, loss: 0.4847, val mf1: 0.5088, (best 0.5275)\n",
      "C: Epoch 343, loss: 0.5613, val mf1: 0.5657, (best 0.5892)\n",
      "s: Epoch 343, loss: 0.3725, val mf1: 0.7736, (best 0.7788)\n",
      "j: Epoch 343, loss: 0.4860, val mf1: 0.5129, (best 0.5275)\n",
      "C: Epoch 344, loss: 0.5609, val mf1: 0.5596, (best 0.5892)\n",
      "s: Epoch 344, loss: 0.3723, val mf1: 0.7736, (best 0.7788)\n",
      "j: Epoch 344, loss: 0.4846, val mf1: 0.5117, (best 0.5275)\n",
      "C: Epoch 345, loss: 0.5606, val mf1: 0.5717, (best 0.5892)\n",
      "s: Epoch 345, loss: 0.3720, val mf1: 0.7742, (best 0.7788)\n",
      "j: Epoch 345, loss: 0.4836, val mf1: 0.5091, (best 0.5275)\n",
      "C: Epoch 346, loss: 0.5596, val mf1: 0.5657, (best 0.5892)\n",
      "s: Epoch 346, loss: 0.3719, val mf1: 0.7742, (best 0.7788)\n",
      "j: Epoch 346, loss: 0.4857, val mf1: 0.5004, (best 0.5275)\n",
      "C: Epoch 347, loss: 0.5594, val mf1: 0.5667, (best 0.5892)\n",
      "s: Epoch 347, loss: 0.3717, val mf1: 0.7735, (best 0.7788)\n",
      "j: Epoch 347, loss: 0.4844, val mf1: 0.5119, (best 0.5275)\n",
      "C: Epoch 348, loss: 0.5593, val mf1: 0.5732, (best 0.5892)\n",
      "s: Epoch 348, loss: 0.3715, val mf1: 0.7754, (best 0.7788)\n",
      "j: Epoch 348, loss: 0.4818, val mf1: 0.5144, (best 0.5275)\n",
      "C: Epoch 349, loss: 0.5585, val mf1: 0.5694, (best 0.5892)\n",
      "s: Epoch 349, loss: 0.3713, val mf1: 0.7735, (best 0.7788)\n",
      "j: Epoch 349, loss: 0.4805, val mf1: 0.5125, (best 0.5275)\n",
      "C: Epoch 350, loss: 0.5582, val mf1: 0.5652, (best 0.5892)\n",
      "s: Epoch 350, loss: 0.3712, val mf1: 0.7736, (best 0.7788)\n",
      "j: Epoch 350, loss: 0.4790, val mf1: 0.5023, (best 0.5275)\n",
      "C: Epoch 351, loss: 0.5576, val mf1: 0.5667, (best 0.5892)\n",
      "s: Epoch 351, loss: 0.3710, val mf1: 0.7741, (best 0.7788)\n",
      "j: Epoch 351, loss: 0.4797, val mf1: 0.5017, (best 0.5275)\n",
      "C: Epoch 352, loss: 0.5570, val mf1: 0.5734, (best 0.5892)\n",
      "s: Epoch 352, loss: 0.3708, val mf1: 0.7748, (best 0.7788)\n",
      "j: Epoch 352, loss: 0.4852, val mf1: 0.5009, (best 0.5275)\n",
      "C: Epoch 353, loss: 0.5567, val mf1: 0.5730, (best 0.5892)\n",
      "s: Epoch 353, loss: 0.3706, val mf1: 0.7742, (best 0.7788)\n",
      "j: Epoch 353, loss: 0.4851, val mf1: 0.5034, (best 0.5275)\n",
      "C: Epoch 354, loss: 0.5564, val mf1: 0.5608, (best 0.5892)\n",
      "s: Epoch 354, loss: 0.3704, val mf1: 0.7742, (best 0.7788)\n",
      "j: Epoch 354, loss: 0.4860, val mf1: 0.5109, (best 0.5275)\n",
      "C: Epoch 355, loss: 0.5563, val mf1: 0.5660, (best 0.5892)\n",
      "s: Epoch 355, loss: 0.3702, val mf1: 0.7735, (best 0.7788)\n",
      "j: Epoch 355, loss: 0.4795, val mf1: 0.5132, (best 0.5275)\n",
      "C: Epoch 356, loss: 0.5563, val mf1: 0.5567, (best 0.5892)\n",
      "s: Epoch 356, loss: 0.3700, val mf1: 0.7742, (best 0.7788)\n",
      "j: Epoch 356, loss: 0.4751, val mf1: 0.5099, (best 0.5275)\n",
      "C: Epoch 357, loss: 0.5623, val mf1: 0.5722, (best 0.5892)\n",
      "s: Epoch 357, loss: 0.3699, val mf1: 0.7737, (best 0.7788)\n",
      "j: Epoch 357, loss: 0.4779, val mf1: 0.5113, (best 0.5275)\n",
      "C: Epoch 358, loss: 0.6027, val mf1: 0.5605, (best 0.5892)\n",
      "s: Epoch 358, loss: 0.3697, val mf1: 0.7748, (best 0.7788)\n",
      "j: Epoch 358, loss: 0.4826, val mf1: 0.5024, (best 0.5275)\n",
      "C: Epoch 359, loss: 0.7481, val mf1: 0.5561, (best 0.5892)\n",
      "s: Epoch 359, loss: 0.3695, val mf1: 0.7725, (best 0.7788)\n",
      "j: Epoch 359, loss: 0.4859, val mf1: 0.5039, (best 0.5275)\n",
      "C: Epoch 360, loss: 0.6044, val mf1: 0.5632, (best 0.5892)\n",
      "s: Epoch 360, loss: 0.3693, val mf1: 0.7726, (best 0.7788)\n",
      "j: Epoch 360, loss: 0.4805, val mf1: 0.5126, (best 0.5275)\n",
      "C: Epoch 361, loss: 0.6435, val mf1: 0.5447, (best 0.5892)\n",
      "s: Epoch 361, loss: 0.3692, val mf1: 0.7727, (best 0.7788)\n",
      "j: Epoch 361, loss: 0.4745, val mf1: 0.5054, (best 0.5275)\n",
      "C: Epoch 362, loss: 0.6210, val mf1: 0.5312, (best 0.5892)\n",
      "s: Epoch 362, loss: 0.3690, val mf1: 0.7720, (best 0.7788)\n",
      "j: Epoch 362, loss: 0.4738, val mf1: 0.5078, (best 0.5275)\n",
      "C: Epoch 363, loss: 0.6141, val mf1: 0.5271, (best 0.5892)\n",
      "s: Epoch 363, loss: 0.3690, val mf1: 0.7715, (best 0.7788)\n",
      "j: Epoch 363, loss: 0.4767, val mf1: 0.5020, (best 0.5275)\n",
      "C: Epoch 364, loss: 0.6090, val mf1: 0.5435, (best 0.5892)\n",
      "s: Epoch 364, loss: 0.3689, val mf1: 0.7737, (best 0.7788)\n",
      "j: Epoch 364, loss: 0.4810, val mf1: 0.4989, (best 0.5275)\n",
      "C: Epoch 365, loss: 0.6123, val mf1: 0.5372, (best 0.5892)\n",
      "s: Epoch 365, loss: 0.3688, val mf1: 0.7747, (best 0.7788)\n",
      "j: Epoch 365, loss: 0.4788, val mf1: 0.5014, (best 0.5275)\n",
      "C: Epoch 366, loss: 0.6143, val mf1: 0.5307, (best 0.5892)\n",
      "s: Epoch 366, loss: 0.3687, val mf1: 0.7739, (best 0.7788)\n",
      "j: Epoch 366, loss: 0.4765, val mf1: 0.5084, (best 0.5275)\n",
      "C: Epoch 367, loss: 0.6154, val mf1: 0.5390, (best 0.5892)\n",
      "s: Epoch 367, loss: 0.3686, val mf1: 0.7741, (best 0.7788)\n",
      "j: Epoch 367, loss: 0.4710, val mf1: 0.5048, (best 0.5275)\n",
      "C: Epoch 368, loss: 0.6145, val mf1: 0.5398, (best 0.5892)\n",
      "s: Epoch 368, loss: 0.3685, val mf1: 0.7750, (best 0.7788)\n",
      "j: Epoch 368, loss: 0.4709, val mf1: 0.4992, (best 0.5275)\n",
      "C: Epoch 369, loss: 0.6099, val mf1: 0.5391, (best 0.5892)\n",
      "s: Epoch 369, loss: 0.3685, val mf1: 0.7773, (best 0.7788)\n",
      "j: Epoch 369, loss: 0.4778, val mf1: 0.5019, (best 0.5275)\n",
      "C: Epoch 370, loss: 0.6079, val mf1: 0.5424, (best 0.5892)\n",
      "s: Epoch 370, loss: 0.3687, val mf1: 0.7729, (best 0.7788)\n",
      "j: Epoch 370, loss: 0.4790, val mf1: 0.5034, (best 0.5275)\n",
      "C: Epoch 371, loss: 0.6078, val mf1: 0.5523, (best 0.5892)\n",
      "s: Epoch 371, loss: 0.3692, val mf1: 0.7775, (best 0.7788)\n",
      "j: Epoch 371, loss: 0.4774, val mf1: 0.5091, (best 0.5275)\n",
      "C: Epoch 372, loss: 0.6085, val mf1: 0.5759, (best 0.5892)\n",
      "s: Epoch 372, loss: 0.3703, val mf1: 0.7760, (best 0.7788)\n",
      "j: Epoch 372, loss: 0.4720, val mf1: 0.5084, (best 0.5275)\n",
      "C: Epoch 373, loss: 0.6076, val mf1: 0.5737, (best 0.5892)\n",
      "s: Epoch 373, loss: 0.3710, val mf1: 0.7778, (best 0.7788)\n",
      "j: Epoch 373, loss: 0.4678, val mf1: 0.5091, (best 0.5275)\n",
      "C: Epoch 374, loss: 0.6048, val mf1: 0.5576, (best 0.5892)\n",
      "s: Epoch 374, loss: 0.3716, val mf1: 0.7747, (best 0.7788)\n",
      "j: Epoch 374, loss: 0.4735, val mf1: 0.5009, (best 0.5275)\n",
      "C: Epoch 375, loss: 0.6013, val mf1: 0.5594, (best 0.5892)\n",
      "s: Epoch 375, loss: 0.3708, val mf1: 0.7784, (best 0.7788)\n",
      "j: Epoch 375, loss: 0.4783, val mf1: 0.5007, (best 0.5275)\n",
      "C: Epoch 376, loss: 0.5983, val mf1: 0.5626, (best 0.5892)\n",
      "s: Epoch 376, loss: 0.3698, val mf1: 0.7749, (best 0.7788)\n",
      "j: Epoch 376, loss: 0.4802, val mf1: 0.5107, (best 0.5275)\n",
      "C: Epoch 377, loss: 0.5963, val mf1: 0.5639, (best 0.5892)\n",
      "s: Epoch 377, loss: 0.3678, val mf1: 0.7775, (best 0.7788)\n",
      "j: Epoch 377, loss: 0.4709, val mf1: 0.5081, (best 0.5275)\n",
      "C: Epoch 378, loss: 0.5966, val mf1: 0.5559, (best 0.5892)\n",
      "s: Epoch 378, loss: 0.3663, val mf1: 0.7752, (best 0.7788)\n",
      "j: Epoch 378, loss: 0.4685, val mf1: 0.5063, (best 0.5275)\n",
      "C: Epoch 379, loss: 0.5950, val mf1: 0.5594, (best 0.5892)\n",
      "s: Epoch 379, loss: 0.3658, val mf1: 0.7761, (best 0.7788)\n",
      "j: Epoch 379, loss: 0.4717, val mf1: 0.5155, (best 0.5275)\n",
      "C: Epoch 380, loss: 0.5937, val mf1: 0.5624, (best 0.5892)\n",
      "s: Epoch 380, loss: 0.3661, val mf1: 0.7765, (best 0.7788)\n",
      "j: Epoch 380, loss: 0.4713, val mf1: 0.4963, (best 0.5275)\n",
      "C: Epoch 381, loss: 0.5893, val mf1: 0.5596, (best 0.5892)\n",
      "s: Epoch 381, loss: 0.3672, val mf1: 0.7752, (best 0.7788)\n",
      "j: Epoch 381, loss: 0.4736, val mf1: 0.4996, (best 0.5275)\n",
      "C: Epoch 382, loss: 0.5895, val mf1: 0.5503, (best 0.5892)\n",
      "s: Epoch 382, loss: 0.3683, val mf1: 0.7766, (best 0.7788)\n",
      "j: Epoch 382, loss: 0.4692, val mf1: 0.5095, (best 0.5275)\n",
      "C: Epoch 383, loss: 0.5864, val mf1: 0.5616, (best 0.5892)\n",
      "s: Epoch 383, loss: 0.3689, val mf1: 0.7741, (best 0.7788)\n",
      "j: Epoch 383, loss: 0.4694, val mf1: 0.5040, (best 0.5275)\n",
      "C: Epoch 384, loss: 0.5866, val mf1: 0.5726, (best 0.5892)\n",
      "s: Epoch 384, loss: 0.3687, val mf1: 0.7784, (best 0.7788)\n",
      "j: Epoch 384, loss: 0.4657, val mf1: 0.5092, (best 0.5275)\n",
      "C: Epoch 385, loss: 0.5837, val mf1: 0.5633, (best 0.5892)\n",
      "s: Epoch 385, loss: 0.3687, val mf1: 0.7752, (best 0.7788)\n",
      "j: Epoch 385, loss: 0.4655, val mf1: 0.5056, (best 0.5275)\n",
      "C: Epoch 386, loss: 0.5827, val mf1: 0.5573, (best 0.5892)\n",
      "s: Epoch 386, loss: 0.3678, val mf1: 0.7766, (best 0.7788)\n",
      "j: Epoch 386, loss: 0.4686, val mf1: 0.5077, (best 0.5275)\n",
      "C: Epoch 387, loss: 0.5799, val mf1: 0.5568, (best 0.5892)\n",
      "s: Epoch 387, loss: 0.3670, val mf1: 0.7752, (best 0.7788)\n",
      "j: Epoch 387, loss: 0.4651, val mf1: 0.4992, (best 0.5275)\n",
      "C: Epoch 388, loss: 0.5798, val mf1: 0.5568, (best 0.5892)\n",
      "s: Epoch 388, loss: 0.3663, val mf1: 0.7801, (best 0.7801)\n",
      "j: Epoch 388, loss: 0.4665, val mf1: 0.5110, (best 0.5275)\n",
      "C: Epoch 389, loss: 0.5785, val mf1: 0.5869, (best 0.5892)\n",
      "s: Epoch 389, loss: 0.3654, val mf1: 0.7782, (best 0.7801)\n",
      "j: Epoch 389, loss: 0.4655, val mf1: 0.5017, (best 0.5275)\n",
      "C: Epoch 390, loss: 0.5787, val mf1: 0.5815, (best 0.5892)\n",
      "s: Epoch 390, loss: 0.3645, val mf1: 0.7779, (best 0.7801)\n",
      "j: Epoch 390, loss: 0.4664, val mf1: 0.5035, (best 0.5275)\n",
      "C: Epoch 391, loss: 0.5770, val mf1: 0.5788, (best 0.5892)\n",
      "s: Epoch 391, loss: 0.3640, val mf1: 0.7788, (best 0.7801)\n",
      "j: Epoch 391, loss: 0.4628, val mf1: 0.5028, (best 0.5275)\n",
      "C: Epoch 392, loss: 0.5783, val mf1: 0.5647, (best 0.5892)\n",
      "s: Epoch 392, loss: 0.3635, val mf1: 0.7753, (best 0.7801)\n",
      "j: Epoch 392, loss: 0.4663, val mf1: 0.5061, (best 0.5275)\n",
      "C: Epoch 393, loss: 0.5765, val mf1: 0.5691, (best 0.5892)\n",
      "s: Epoch 393, loss: 0.3631, val mf1: 0.7784, (best 0.7801)\n",
      "j: Epoch 393, loss: 0.4678, val mf1: 0.5099, (best 0.5275)\n",
      "C: Epoch 394, loss: 0.5757, val mf1: 0.5779, (best 0.5892)\n",
      "s: Epoch 394, loss: 0.3628, val mf1: 0.7755, (best 0.7801)\n",
      "j: Epoch 394, loss: 0.4648, val mf1: 0.5065, (best 0.5275)\n",
      "C: Epoch 395, loss: 0.5761, val mf1: 0.5653, (best 0.5892)\n",
      "s: Epoch 395, loss: 0.3626, val mf1: 0.7787, (best 0.7801)\n",
      "j: Epoch 395, loss: 0.4622, val mf1: 0.5024, (best 0.5275)\n",
      "C: Epoch 396, loss: 0.5729, val mf1: 0.5705, (best 0.5892)\n",
      "s: Epoch 396, loss: 0.3628, val mf1: 0.7782, (best 0.7801)\n",
      "j: Epoch 396, loss: 0.4638, val mf1: 0.5047, (best 0.5275)\n",
      "C: Epoch 397, loss: 0.5735, val mf1: 0.5853, (best 0.5892)\n",
      "s: Epoch 397, loss: 0.3633, val mf1: 0.7787, (best 0.7801)\n",
      "j: Epoch 397, loss: 0.4636, val mf1: 0.5044, (best 0.5275)\n",
      "C: Epoch 398, loss: 0.5720, val mf1: 0.5737, (best 0.5892)\n",
      "s: Epoch 398, loss: 0.3644, val mf1: 0.7788, (best 0.7801)\n",
      "j: Epoch 398, loss: 0.4608, val mf1: 0.5042, (best 0.5275)\n",
      "C: Epoch 399, loss: 0.5722, val mf1: 0.5591, (best 0.5892)\n",
      "s: Epoch 399, loss: 0.3667, val mf1: 0.7756, (best 0.7801)\n",
      "j: Epoch 399, loss: 0.4611, val mf1: 0.5041, (best 0.5275)\n",
      "C: Epoch 400, loss: 0.5705, val mf1: 0.5679, (best 0.5892)\n",
      "s: Epoch 400, loss: 0.3710, val mf1: 0.7756, (best 0.7801)\n",
      "j: Epoch 400, loss: 0.4585, val mf1: 0.5039, (best 0.5275)\n",
      "C: Epoch 401, loss: 0.5699, val mf1: 0.5639, (best 0.5892)\n",
      "s: Epoch 401, loss: 0.3743, val mf1: 0.7738, (best 0.7801)\n",
      "j: Epoch 401, loss: 0.4577, val mf1: 0.5031, (best 0.5275)\n",
      "C: Epoch 402, loss: 0.5702, val mf1: 0.5582, (best 0.5892)\n",
      "s: Epoch 402, loss: 0.3769, val mf1: 0.7758, (best 0.7801)\n",
      "j: Epoch 402, loss: 0.4573, val mf1: 0.5041, (best 0.5275)\n",
      "C: Epoch 403, loss: 0.5690, val mf1: 0.5594, (best 0.5892)\n",
      "s: Epoch 403, loss: 0.3711, val mf1: 0.7752, (best 0.7801)\n",
      "j: Epoch 403, loss: 0.4564, val mf1: 0.5029, (best 0.5275)\n",
      "C: Epoch 404, loss: 0.5686, val mf1: 0.5713, (best 0.5892)\n",
      "s: Epoch 404, loss: 0.3646, val mf1: 0.7818, (best 0.7818)\n",
      "j: Epoch 404, loss: 0.4590, val mf1: 0.4996, (best 0.5275)\n",
      "C: Epoch 405, loss: 0.5687, val mf1: 0.5585, (best 0.5892)\n",
      "s: Epoch 405, loss: 0.3608, val mf1: 0.7806, (best 0.7818)\n",
      "j: Epoch 405, loss: 0.4593, val mf1: 0.4989, (best 0.5275)\n",
      "C: Epoch 406, loss: 0.5681, val mf1: 0.5610, (best 0.5892)\n",
      "s: Epoch 406, loss: 0.3615, val mf1: 0.7770, (best 0.7818)\n",
      "j: Epoch 406, loss: 0.4594, val mf1: 0.5037, (best 0.5275)\n",
      "C: Epoch 407, loss: 0.5678, val mf1: 0.5717, (best 0.5892)\n",
      "s: Epoch 407, loss: 0.3646, val mf1: 0.7781, (best 0.7818)\n",
      "j: Epoch 407, loss: 0.4550, val mf1: 0.4998, (best 0.5275)\n",
      "C: Epoch 408, loss: 0.5666, val mf1: 0.5552, (best 0.5892)\n",
      "s: Epoch 408, loss: 0.3678, val mf1: 0.7745, (best 0.7818)\n",
      "j: Epoch 408, loss: 0.4572, val mf1: 0.4982, (best 0.5275)\n",
      "C: Epoch 409, loss: 0.5668, val mf1: 0.5608, (best 0.5892)\n",
      "s: Epoch 409, loss: 0.3653, val mf1: 0.7794, (best 0.7818)\n",
      "j: Epoch 409, loss: 0.4586, val mf1: 0.5102, (best 0.5275)\n",
      "C: Epoch 410, loss: 0.5658, val mf1: 0.5585, (best 0.5892)\n",
      "s: Epoch 410, loss: 0.3615, val mf1: 0.7790, (best 0.7818)\n",
      "j: Epoch 410, loss: 0.4543, val mf1: 0.5034, (best 0.5275)\n",
      "C: Epoch 411, loss: 0.5651, val mf1: 0.5547, (best 0.5892)\n",
      "s: Epoch 411, loss: 0.3597, val mf1: 0.7776, (best 0.7818)\n",
      "j: Epoch 411, loss: 0.4521, val mf1: 0.5073, (best 0.5275)\n",
      "C: Epoch 412, loss: 0.5655, val mf1: 0.5623, (best 0.5892)\n",
      "s: Epoch 412, loss: 0.3611, val mf1: 0.7764, (best 0.7818)\n",
      "j: Epoch 412, loss: 0.4522, val mf1: 0.5088, (best 0.5275)\n",
      "C: Epoch 413, loss: 0.5643, val mf1: 0.5559, (best 0.5892)\n",
      "s: Epoch 413, loss: 0.3627, val mf1: 0.7806, (best 0.7818)\n",
      "j: Epoch 413, loss: 0.4539, val mf1: 0.5034, (best 0.5275)\n",
      "C: Epoch 414, loss: 0.5640, val mf1: 0.5635, (best 0.5892)\n",
      "s: Epoch 414, loss: 0.3636, val mf1: 0.7793, (best 0.7818)\n",
      "j: Epoch 414, loss: 0.4531, val mf1: 0.5049, (best 0.5275)\n",
      "C: Epoch 415, loss: 0.5637, val mf1: 0.5533, (best 0.5892)\n",
      "s: Epoch 415, loss: 0.3619, val mf1: 0.7810, (best 0.7818)\n",
      "j: Epoch 415, loss: 0.4528, val mf1: 0.4996, (best 0.5275)\n",
      "C: Epoch 416, loss: 0.5641, val mf1: 0.5549, (best 0.5892)\n",
      "s: Epoch 416, loss: 0.3591, val mf1: 0.7780, (best 0.7818)\n",
      "j: Epoch 416, loss: 0.4567, val mf1: 0.5006, (best 0.5275)\n",
      "C: Epoch 417, loss: 0.5630, val mf1: 0.5504, (best 0.5892)\n",
      "s: Epoch 417, loss: 0.3581, val mf1: 0.7804, (best 0.7818)\n",
      "j: Epoch 417, loss: 0.4548, val mf1: 0.5072, (best 0.5275)\n",
      "C: Epoch 418, loss: 0.5627, val mf1: 0.5625, (best 0.5892)\n",
      "s: Epoch 418, loss: 0.3587, val mf1: 0.7805, (best 0.7818)\n",
      "j: Epoch 418, loss: 0.4554, val mf1: 0.5004, (best 0.5275)\n",
      "C: Epoch 419, loss: 0.5616, val mf1: 0.5539, (best 0.5892)\n",
      "s: Epoch 419, loss: 0.3595, val mf1: 0.7800, (best 0.7818)\n",
      "j: Epoch 419, loss: 0.4511, val mf1: 0.5052, (best 0.5275)\n",
      "C: Epoch 420, loss: 0.5613, val mf1: 0.5581, (best 0.5892)\n",
      "s: Epoch 420, loss: 0.3603, val mf1: 0.7784, (best 0.7818)\n",
      "j: Epoch 420, loss: 0.4523, val mf1: 0.5034, (best 0.5275)\n",
      "C: Epoch 421, loss: 0.5610, val mf1: 0.5525, (best 0.5892)\n",
      "s: Epoch 421, loss: 0.3611, val mf1: 0.7793, (best 0.7818)\n",
      "j: Epoch 421, loss: 0.4523, val mf1: 0.4997, (best 0.5275)\n",
      "C: Epoch 422, loss: 0.5614, val mf1: 0.5560, (best 0.5892)\n",
      "s: Epoch 422, loss: 0.3606, val mf1: 0.7786, (best 0.7818)\n",
      "j: Epoch 422, loss: 0.4570, val mf1: 0.5010, (best 0.5275)\n",
      "C: Epoch 423, loss: 0.5602, val mf1: 0.5550, (best 0.5892)\n",
      "s: Epoch 423, loss: 0.3603, val mf1: 0.7793, (best 0.7818)\n",
      "j: Epoch 423, loss: 0.4602, val mf1: 0.5049, (best 0.5275)\n",
      "C: Epoch 424, loss: 0.5614, val mf1: 0.5580, (best 0.5892)\n",
      "s: Epoch 424, loss: 0.3587, val mf1: 0.7761, (best 0.7818)\n",
      "j: Epoch 424, loss: 0.4570, val mf1: 0.5044, (best 0.5275)\n",
      "C: Epoch 425, loss: 0.5592, val mf1: 0.5507, (best 0.5892)\n",
      "s: Epoch 425, loss: 0.3569, val mf1: 0.7826, (best 0.7826)\n",
      "j: Epoch 425, loss: 0.4537, val mf1: 0.5026, (best 0.5275)\n",
      "C: Epoch 426, loss: 0.5594, val mf1: 0.5531, (best 0.5892)\n",
      "s: Epoch 426, loss: 0.3564, val mf1: 0.7835, (best 0.7835)\n",
      "j: Epoch 426, loss: 0.4493, val mf1: 0.5082, (best 0.5275)\n",
      "C: Epoch 427, loss: 0.5591, val mf1: 0.5576, (best 0.5892)\n",
      "s: Epoch 427, loss: 0.3562, val mf1: 0.7809, (best 0.7835)\n",
      "j: Epoch 427, loss: 0.4573, val mf1: 0.5040, (best 0.5275)\n",
      "C: Epoch 428, loss: 0.5586, val mf1: 0.5555, (best 0.5892)\n",
      "s: Epoch 428, loss: 0.3567, val mf1: 0.7823, (best 0.7835)\n",
      "j: Epoch 428, loss: 0.4508, val mf1: 0.5049, (best 0.5275)\n",
      "C: Epoch 429, loss: 0.5578, val mf1: 0.5526, (best 0.5892)\n",
      "s: Epoch 429, loss: 0.3573, val mf1: 0.7800, (best 0.7835)\n",
      "j: Epoch 429, loss: 0.4618, val mf1: 0.4998, (best 0.5275)\n",
      "C: Epoch 430, loss: 0.5578, val mf1: 0.5517, (best 0.5892)\n",
      "s: Epoch 430, loss: 0.3578, val mf1: 0.7794, (best 0.7835)\n",
      "j: Epoch 430, loss: 0.4641, val mf1: 0.5074, (best 0.5275)\n",
      "C: Epoch 431, loss: 0.5580, val mf1: 0.5584, (best 0.5892)\n",
      "s: Epoch 431, loss: 0.3578, val mf1: 0.7802, (best 0.7835)\n",
      "j: Epoch 431, loss: 0.4623, val mf1: 0.5030, (best 0.5275)\n",
      "C: Epoch 432, loss: 0.5565, val mf1: 0.5651, (best 0.5892)\n",
      "s: Epoch 432, loss: 0.3577, val mf1: 0.7787, (best 0.7835)\n",
      "j: Epoch 432, loss: 0.4471, val mf1: 0.4992, (best 0.5275)\n",
      "C: Epoch 433, loss: 0.5575, val mf1: 0.5610, (best 0.5892)\n",
      "s: Epoch 433, loss: 0.3575, val mf1: 0.7784, (best 0.7835)\n",
      "j: Epoch 433, loss: 0.4549, val mf1: 0.4998, (best 0.5275)\n",
      "C: Epoch 434, loss: 0.5565, val mf1: 0.5526, (best 0.5892)\n",
      "s: Epoch 434, loss: 0.3571, val mf1: 0.7814, (best 0.7835)\n",
      "j: Epoch 434, loss: 0.4438, val mf1: 0.5014, (best 0.5275)\n",
      "C: Epoch 435, loss: 0.5555, val mf1: 0.5625, (best 0.5892)\n",
      "s: Epoch 435, loss: 0.3561, val mf1: 0.7765, (best 0.7835)\n",
      "j: Epoch 435, loss: 0.4524, val mf1: 0.5017, (best 0.5275)\n",
      "C: Epoch 436, loss: 0.5554, val mf1: 0.5584, (best 0.5892)\n",
      "s: Epoch 436, loss: 0.3553, val mf1: 0.7812, (best 0.7835)\n",
      "j: Epoch 436, loss: 0.4470, val mf1: 0.5081, (best 0.5275)\n",
      "C: Epoch 437, loss: 0.5563, val mf1: 0.5574, (best 0.5892)\n",
      "s: Epoch 437, loss: 0.3547, val mf1: 0.7782, (best 0.7835)\n",
      "j: Epoch 437, loss: 0.4520, val mf1: 0.5024, (best 0.5275)\n",
      "C: Epoch 438, loss: 0.5566, val mf1: 0.5584, (best 0.5892)\n",
      "s: Epoch 438, loss: 0.3542, val mf1: 0.7816, (best 0.7835)\n",
      "j: Epoch 438, loss: 0.4448, val mf1: 0.5039, (best 0.5275)\n",
      "C: Epoch 439, loss: 0.5558, val mf1: 0.5536, (best 0.5892)\n",
      "s: Epoch 439, loss: 0.3539, val mf1: 0.7845, (best 0.7845)\n",
      "j: Epoch 439, loss: 0.4515, val mf1: 0.5030, (best 0.5275)\n",
      "C: Epoch 440, loss: 0.5548, val mf1: 0.5527, (best 0.5892)\n",
      "s: Epoch 440, loss: 0.3537, val mf1: 0.7819, (best 0.7845)\n",
      "j: Epoch 440, loss: 0.4476, val mf1: 0.4980, (best 0.5275)\n",
      "C: Epoch 441, loss: 0.5545, val mf1: 0.5485, (best 0.5892)\n",
      "s: Epoch 441, loss: 0.3536, val mf1: 0.7814, (best 0.7845)\n",
      "j: Epoch 441, loss: 0.4506, val mf1: 0.4976, (best 0.5275)\n",
      "C: Epoch 442, loss: 0.5542, val mf1: 0.5655, (best 0.5892)\n",
      "s: Epoch 442, loss: 0.3534, val mf1: 0.7811, (best 0.7845)\n",
      "j: Epoch 442, loss: 0.4468, val mf1: 0.5032, (best 0.5275)\n",
      "C: Epoch 443, loss: 0.5545, val mf1: 0.5614, (best 0.5892)\n",
      "s: Epoch 443, loss: 0.3534, val mf1: 0.7804, (best 0.7845)\n",
      "j: Epoch 443, loss: 0.4475, val mf1: 0.5039, (best 0.5275)\n",
      "C: Epoch 444, loss: 0.5586, val mf1: 0.5533, (best 0.5892)\n",
      "s: Epoch 444, loss: 0.3533, val mf1: 0.7840, (best 0.7845)\n",
      "j: Epoch 444, loss: 0.4469, val mf1: 0.5042, (best 0.5275)\n",
      "C: Epoch 445, loss: 0.5564, val mf1: 0.5560, (best 0.5892)\n",
      "s: Epoch 445, loss: 0.3536, val mf1: 0.7800, (best 0.7845)\n",
      "j: Epoch 445, loss: 0.4486, val mf1: 0.5030, (best 0.5275)\n",
      "C: Epoch 446, loss: 0.5538, val mf1: 0.5580, (best 0.5892)\n",
      "s: Epoch 446, loss: 0.3543, val mf1: 0.7814, (best 0.7845)\n",
      "j: Epoch 446, loss: 0.4443, val mf1: 0.5058, (best 0.5275)\n",
      "C: Epoch 447, loss: 0.5576, val mf1: 0.5572, (best 0.5892)\n",
      "s: Epoch 447, loss: 0.3558, val mf1: 0.7773, (best 0.7845)\n",
      "j: Epoch 447, loss: 0.4488, val mf1: 0.4993, (best 0.5275)\n",
      "C: Epoch 448, loss: 0.5578, val mf1: 0.5544, (best 0.5892)\n",
      "s: Epoch 448, loss: 0.3588, val mf1: 0.7816, (best 0.7845)\n",
      "j: Epoch 448, loss: 0.4440, val mf1: 0.5054, (best 0.5275)\n",
      "C: Epoch 449, loss: 0.5557, val mf1: 0.5608, (best 0.5892)\n",
      "s: Epoch 449, loss: 0.3635, val mf1: 0.7776, (best 0.7845)\n",
      "j: Epoch 449, loss: 0.4416, val mf1: 0.4998, (best 0.5275)\n",
      "C: Epoch 450, loss: 0.5529, val mf1: 0.5657, (best 0.5892)\n",
      "s: Epoch 450, loss: 0.3695, val mf1: 0.7788, (best 0.7845)\n",
      "j: Epoch 450, loss: 0.4375, val mf1: 0.5007, (best 0.5275)\n",
      "C: Epoch 451, loss: 0.5576, val mf1: 0.5682, (best 0.5892)\n",
      "s: Epoch 451, loss: 0.3678, val mf1: 0.7776, (best 0.7845)\n",
      "j: Epoch 451, loss: 0.4433, val mf1: 0.5030, (best 0.5275)\n",
      "C: Epoch 452, loss: 0.5569, val mf1: 0.5616, (best 0.5892)\n",
      "s: Epoch 452, loss: 0.3644, val mf1: 0.7794, (best 0.7845)\n",
      "j: Epoch 452, loss: 0.4420, val mf1: 0.5102, (best 0.5275)\n",
      "C: Epoch 453, loss: 0.5526, val mf1: 0.5526, (best 0.5892)\n",
      "s: Epoch 453, loss: 0.3572, val mf1: 0.7799, (best 0.7845)\n",
      "j: Epoch 453, loss: 0.4421, val mf1: 0.5129, (best 0.5275)\n",
      "C: Epoch 454, loss: 0.5541, val mf1: 0.5570, (best 0.5892)\n",
      "s: Epoch 454, loss: 0.3521, val mf1: 0.7841, (best 0.7845)\n",
      "j: Epoch 454, loss: 0.4420, val mf1: 0.5080, (best 0.5275)\n",
      "C: Epoch 455, loss: 0.5549, val mf1: 0.5594, (best 0.5892)\n",
      "s: Epoch 455, loss: 0.3532, val mf1: 0.7824, (best 0.7845)\n",
      "j: Epoch 455, loss: 0.4445, val mf1: 0.5041, (best 0.5275)\n",
      "C: Epoch 456, loss: 0.5517, val mf1: 0.5591, (best 0.5892)\n",
      "s: Epoch 456, loss: 0.3572, val mf1: 0.7816, (best 0.7845)\n",
      "j: Epoch 456, loss: 0.4419, val mf1: 0.4983, (best 0.5275)\n",
      "C: Epoch 457, loss: 0.5524, val mf1: 0.5604, (best 0.5892)\n",
      "s: Epoch 457, loss: 0.3615, val mf1: 0.7800, (best 0.7845)\n",
      "j: Epoch 457, loss: 0.4418, val mf1: 0.5050, (best 0.5275)\n",
      "C: Epoch 458, loss: 0.5546, val mf1: 0.5604, (best 0.5892)\n",
      "s: Epoch 458, loss: 0.3662, val mf1: 0.7764, (best 0.7845)\n",
      "j: Epoch 458, loss: 0.4337, val mf1: 0.5017, (best 0.5275)\n",
      "C: Epoch 459, loss: 0.5526, val mf1: 0.5602, (best 0.5892)\n",
      "s: Epoch 459, loss: 0.3618, val mf1: 0.7794, (best 0.7845)\n",
      "j: Epoch 459, loss: 0.4452, val mf1: 0.5020, (best 0.5275)\n",
      "C: Epoch 460, loss: 0.5551, val mf1: 0.5641, (best 0.5892)\n",
      "s: Epoch 460, loss: 0.3554, val mf1: 0.7837, (best 0.7845)\n",
      "j: Epoch 460, loss: 0.4402, val mf1: 0.5136, (best 0.5275)\n",
      "C: Epoch 461, loss: 0.5551, val mf1: 0.5620, (best 0.5892)\n",
      "s: Epoch 461, loss: 0.3512, val mf1: 0.7806, (best 0.7845)\n",
      "j: Epoch 461, loss: 0.4349, val mf1: 0.5095, (best 0.5275)\n",
      "C: Epoch 462, loss: 0.5519, val mf1: 0.5614, (best 0.5892)\n",
      "s: Epoch 462, loss: 0.3535, val mf1: 0.7818, (best 0.7845)\n",
      "j: Epoch 462, loss: 0.4408, val mf1: 0.5017, (best 0.5275)\n",
      "C: Epoch 463, loss: 0.5551, val mf1: 0.5689, (best 0.5892)\n",
      "s: Epoch 463, loss: 0.3567, val mf1: 0.7776, (best 0.7845)\n",
      "j: Epoch 463, loss: 0.4408, val mf1: 0.5079, (best 0.5275)\n",
      "C: Epoch 464, loss: 0.5529, val mf1: 0.5625, (best 0.5892)\n",
      "s: Epoch 464, loss: 0.3585, val mf1: 0.7818, (best 0.7845)\n",
      "j: Epoch 464, loss: 0.4319, val mf1: 0.4998, (best 0.5275)\n",
      "C: Epoch 465, loss: 0.5528, val mf1: 0.5696, (best 0.5892)\n",
      "s: Epoch 465, loss: 0.3574, val mf1: 0.7824, (best 0.7845)\n",
      "j: Epoch 465, loss: 0.4401, val mf1: 0.5044, (best 0.5275)\n",
      "C: Epoch 466, loss: 0.5520, val mf1: 0.5605, (best 0.5892)\n",
      "s: Epoch 466, loss: 0.3516, val mf1: 0.7832, (best 0.7845)\n",
      "j: Epoch 466, loss: 0.4492, val mf1: 0.5114, (best 0.5275)\n",
      "C: Epoch 467, loss: 0.5509, val mf1: 0.5633, (best 0.5892)\n",
      "s: Epoch 467, loss: 0.3511, val mf1: 0.7790, (best 0.7845)\n",
      "j: Epoch 467, loss: 0.4374, val mf1: 0.5047, (best 0.5275)\n",
      "C: Epoch 468, loss: 0.5543, val mf1: 0.5639, (best 0.5892)\n",
      "s: Epoch 468, loss: 0.3546, val mf1: 0.7803, (best 0.7845)\n",
      "j: Epoch 468, loss: 0.4433, val mf1: 0.5044, (best 0.5275)\n",
      "C: Epoch 469, loss: 0.5512, val mf1: 0.5611, (best 0.5892)\n",
      "s: Epoch 469, loss: 0.3565, val mf1: 0.7812, (best 0.7845)\n",
      "j: Epoch 469, loss: 0.4412, val mf1: 0.5095, (best 0.5275)\n",
      "C: Epoch 470, loss: 0.5539, val mf1: 0.5710, (best 0.5892)\n",
      "s: Epoch 470, loss: 0.3551, val mf1: 0.7785, (best 0.7845)\n",
      "j: Epoch 470, loss: 0.4408, val mf1: 0.5044, (best 0.5275)\n",
      "C: Epoch 471, loss: 0.5508, val mf1: 0.5565, (best 0.5892)\n",
      "s: Epoch 471, loss: 0.3517, val mf1: 0.7830, (best 0.7845)\n",
      "j: Epoch 471, loss: 0.4475, val mf1: 0.5041, (best 0.5275)\n",
      "C: Epoch 472, loss: 0.5531, val mf1: 0.5597, (best 0.5892)\n",
      "s: Epoch 472, loss: 0.3507, val mf1: 0.7800, (best 0.7845)\n",
      "j: Epoch 472, loss: 0.4394, val mf1: 0.5125, (best 0.5275)\n",
      "C: Epoch 473, loss: 0.5528, val mf1: 0.5647, (best 0.5892)\n",
      "s: Epoch 473, loss: 0.3504, val mf1: 0.7791, (best 0.7845)\n",
      "j: Epoch 473, loss: 0.4425, val mf1: 0.5081, (best 0.5275)\n",
      "C: Epoch 474, loss: 0.5506, val mf1: 0.5617, (best 0.5892)\n",
      "s: Epoch 474, loss: 0.3510, val mf1: 0.7818, (best 0.7845)\n",
      "j: Epoch 474, loss: 0.4438, val mf1: 0.5022, (best 0.5275)\n",
      "C: Epoch 475, loss: 0.5518, val mf1: 0.5643, (best 0.5892)\n",
      "s: Epoch 475, loss: 0.3522, val mf1: 0.7809, (best 0.7845)\n",
      "j: Epoch 475, loss: 0.4347, val mf1: 0.5055, (best 0.5275)\n",
      "C: Epoch 476, loss: 0.5505, val mf1: 0.5630, (best 0.5892)\n",
      "s: Epoch 476, loss: 0.3506, val mf1: 0.7848, (best 0.7848)\n",
      "j: Epoch 476, loss: 0.4446, val mf1: 0.5044, (best 0.5275)\n",
      "C: Epoch 477, loss: 0.5524, val mf1: 0.5619, (best 0.5892)\n",
      "s: Epoch 477, loss: 0.3493, val mf1: 0.7847, (best 0.7848)\n",
      "j: Epoch 477, loss: 0.4369, val mf1: 0.5040, (best 0.5275)\n",
      "C: Epoch 478, loss: 0.5515, val mf1: 0.5588, (best 0.5892)\n",
      "s: Epoch 478, loss: 0.3489, val mf1: 0.7806, (best 0.7848)\n",
      "j: Epoch 478, loss: 0.4358, val mf1: 0.5020, (best 0.5275)\n",
      "C: Epoch 479, loss: 0.5505, val mf1: 0.5573, (best 0.5892)\n",
      "s: Epoch 479, loss: 0.3487, val mf1: 0.7818, (best 0.7848)\n",
      "j: Epoch 479, loss: 0.4432, val mf1: 0.5047, (best 0.5275)\n",
      "C: Epoch 480, loss: 0.5544, val mf1: 0.5591, (best 0.5892)\n",
      "s: Epoch 480, loss: 0.3497, val mf1: 0.7795, (best 0.7848)\n",
      "j: Epoch 480, loss: 0.4319, val mf1: 0.5014, (best 0.5275)\n",
      "C: Epoch 481, loss: 0.5503, val mf1: 0.5616, (best 0.5892)\n",
      "s: Epoch 481, loss: 0.3510, val mf1: 0.7806, (best 0.7848)\n",
      "j: Epoch 481, loss: 0.4335, val mf1: 0.5027, (best 0.5275)\n",
      "C: Epoch 482, loss: 0.5508, val mf1: 0.5577, (best 0.5892)\n",
      "s: Epoch 482, loss: 0.3511, val mf1: 0.7788, (best 0.7848)\n",
      "j: Epoch 482, loss: 0.4378, val mf1: 0.5034, (best 0.5275)\n",
      "C: Epoch 483, loss: 0.5504, val mf1: 0.5594, (best 0.5892)\n",
      "s: Epoch 483, loss: 0.3511, val mf1: 0.7830, (best 0.7848)\n",
      "j: Epoch 483, loss: 0.4284, val mf1: 0.5034, (best 0.5275)\n",
      "C: Epoch 484, loss: 0.5484, val mf1: 0.5616, (best 0.5892)\n",
      "s: Epoch 484, loss: 0.3508, val mf1: 0.7789, (best 0.7848)\n",
      "j: Epoch 484, loss: 0.4368, val mf1: 0.5054, (best 0.5275)\n",
      "C: Epoch 485, loss: 0.5499, val mf1: 0.5582, (best 0.5892)\n",
      "s: Epoch 485, loss: 0.3489, val mf1: 0.7833, (best 0.7848)\n",
      "j: Epoch 485, loss: 0.4331, val mf1: 0.5110, (best 0.5275)\n",
      "C: Epoch 486, loss: 0.5490, val mf1: 0.5641, (best 0.5892)\n",
      "s: Epoch 486, loss: 0.3481, val mf1: 0.7834, (best 0.7848)\n",
      "j: Epoch 486, loss: 0.4285, val mf1: 0.5014, (best 0.5275)\n",
      "C: Epoch 487, loss: 0.5476, val mf1: 0.5621, (best 0.5892)\n",
      "s: Epoch 487, loss: 0.3475, val mf1: 0.7809, (best 0.7848)\n",
      "j: Epoch 487, loss: 0.4385, val mf1: 0.5037, (best 0.5275)\n",
      "C: Epoch 488, loss: 0.5481, val mf1: 0.5554, (best 0.5892)\n",
      "s: Epoch 488, loss: 0.3481, val mf1: 0.7839, (best 0.7848)\n",
      "j: Epoch 488, loss: 0.4267, val mf1: 0.5014, (best 0.5275)\n",
      "C: Epoch 489, loss: 0.5484, val mf1: 0.5584, (best 0.5892)\n",
      "s: Epoch 489, loss: 0.3488, val mf1: 0.7804, (best 0.7848)\n",
      "j: Epoch 489, loss: 0.4338, val mf1: 0.5054, (best 0.5275)\n",
      "C: Epoch 490, loss: 0.5482, val mf1: 0.5625, (best 0.5892)\n",
      "s: Epoch 490, loss: 0.3500, val mf1: 0.7824, (best 0.7848)\n",
      "j: Epoch 490, loss: 0.4284, val mf1: 0.5034, (best 0.5275)\n",
      "C: Epoch 491, loss: 0.5474, val mf1: 0.5589, (best 0.5892)\n",
      "s: Epoch 491, loss: 0.3527, val mf1: 0.7806, (best 0.7848)\n",
      "j: Epoch 491, loss: 0.4355, val mf1: 0.5014, (best 0.5275)\n",
      "C: Epoch 492, loss: 0.5476, val mf1: 0.5579, (best 0.5892)\n",
      "s: Epoch 492, loss: 0.3519, val mf1: 0.7812, (best 0.7848)\n",
      "j: Epoch 492, loss: 0.4367, val mf1: 0.5120, (best 0.5275)\n",
      "C: Epoch 493, loss: 0.5471, val mf1: 0.5610, (best 0.5892)\n",
      "s: Epoch 493, loss: 0.3516, val mf1: 0.7800, (best 0.7848)\n",
      "j: Epoch 493, loss: 0.4287, val mf1: 0.5042, (best 0.5275)\n",
      "C: Epoch 494, loss: 0.5469, val mf1: 0.5541, (best 0.5892)\n",
      "s: Epoch 494, loss: 0.3513, val mf1: 0.7852, (best 0.7852)\n",
      "j: Epoch 494, loss: 0.4421, val mf1: 0.5007, (best 0.5275)\n",
      "C: Epoch 495, loss: 0.5482, val mf1: 0.5547, (best 0.5892)\n",
      "s: Epoch 495, loss: 0.3491, val mf1: 0.7844, (best 0.7852)\n",
      "j: Epoch 495, loss: 0.4303, val mf1: 0.5037, (best 0.5275)\n",
      "C: Epoch 496, loss: 0.5462, val mf1: 0.5607, (best 0.5892)\n",
      "s: Epoch 496, loss: 0.3466, val mf1: 0.7842, (best 0.7852)\n",
      "j: Epoch 496, loss: 0.4313, val mf1: 0.5051, (best 0.5275)\n",
      "C: Epoch 497, loss: 0.5472, val mf1: 0.5579, (best 0.5892)\n",
      "s: Epoch 497, loss: 0.3475, val mf1: 0.7842, (best 0.7852)\n",
      "j: Epoch 497, loss: 0.4383, val mf1: 0.5069, (best 0.5275)\n",
      "C: Epoch 498, loss: 0.5462, val mf1: 0.5630, (best 0.5892)\n",
      "s: Epoch 498, loss: 0.3473, val mf1: 0.7804, (best 0.7852)\n",
      "j: Epoch 498, loss: 0.4431, val mf1: 0.5043, (best 0.5275)\n",
      "C: Epoch 499, loss: 0.5462, val mf1: 0.5538, (best 0.5892)\n",
      "s: Epoch 499, loss: 0.3478, val mf1: 0.7872, (best 0.7872)\n",
      "j: Epoch 499, loss: 0.4357, val mf1: 0.5056, (best 0.5275)\n",
      "time cost:  196.15009784698486 s\n",
      "Test_c: REC 22.30 PRE 16.58 MF1 57.46 AUC 71.14\n",
      "Test_s: REC 79.60 PRE 81.18 MF1 79.92 AUC 89.63\n",
      "Test_j: REC 6.90 PRE 6.67 MF1 50.81 AUC 49.21\n",
      "MF1-mean_c: 57.46, MF1-std: 0.00, AUC-mean: 71.14, AUC-std: 0.00\n",
      "MF1-mean_s: 79.92, MF1-std: 0.00, AUC-mean: 89.63, AUC-std: 0.00\n",
      "MF1-mean_j: 50.81, MF1-std: 0.00, AUC-mean: 49.21, AUC-std: 0.00\n"
     ]
    }
   ],
   "source": [
    "h_feats_c = args.hid_dim_c\n",
    "in_feats_c = data.x.shape[1]\n",
    "h_feats_s = args.hid_dim_s\n",
    "in_feats_s = neighbor_spectral_features.shape[1]\n",
    "h_feats_j = args.hid_dim_j\n",
    "in_feats_j = neighbor_spectral_features.shape[1]\n",
    "num_classes = 2\n",
    "\n",
    "if args.run == 0:\n",
    "    model_c = ChebConvGAD_c(in_feats_c, h_feats_c, num_classes, k = args.k_c)\n",
    "    model_s = ChebConvGAD_s(in_feats_s, h_feats_s, num_classes, k = args.k_s)\n",
    "    model_j = ChebConvGAD_j(in_feats_j, h_feats_j, num_classes, k = args.k_j)\n",
    "    \n",
    "    train(model_c, model_s, model_j, data, neighbor_spectral_features, ys, yj, args)\n",
    "\n",
    "else:\n",
    "    final_mf1s_c, final_aucs_c,final_mf1s_s, final_aucs_s, final_mf1s_j, final_aucs_j= [], [], [], [], [], []\n",
    "    for tt in range(args.run):\n",
    "\n",
    "        #in_feats 特征点维度；h_feats：隐层维度；num_classes：节点分类数（nomal，anomaly）\n",
    "        model_c = ChebConvGAD_c(in_feats_c, h_feats_c, num_classes, k = args.k_c)\n",
    "        model_s = ChebConvGAD_s(in_feats_s, h_feats_s, num_classes, k = args.k_s)\n",
    "        model_j = ChebConvGAD_j(in_feats_j, h_feats_j, num_classes, k = args.k_j)\n",
    "        mf1_c, auc_c, mf1_s, auc_s, mf1_j, auc_j = train(model_c, model_s, model_j, data, neighbor_spectral_features, ys, yj, args)\n",
    "        \n",
    "        final_mf1s_c.append(mf1_c)\n",
    "        final_aucs_c.append(auc_c)\n",
    "        final_mf1s_s.append(mf1_s)\n",
    "        final_aucs_s.append(auc_s)\n",
    "        final_mf1s_j.append(mf1_j)\n",
    "        final_aucs_j.append(auc_j)\n",
    "    final_mf1s_c = np.array(final_mf1s_c)\n",
    "    final_aucs_c = np.array(final_aucs_c)\n",
    "    # np.std :计算全局标准差\n",
    "    print('MF1-mean_c: {:.2f}, MF1-std: {:.2f}, AUC-mean: {:.2f}, AUC-std: {:.2f}'.format(100 * np.mean(final_mf1s_c),\n",
    "                                                                                            100 * np.std(final_mf1s_c),\n",
    "                                                               100 * np.mean(final_aucs_c), 100 * np.std(final_aucs_c)))\n",
    "\n",
    "    final_mf1s_s = np.array(final_mf1s_s)\n",
    "    final_aucs_s = np.array(final_aucs_s)\n",
    "    # np.std :计算全局标准差\n",
    "    print('MF1-mean_s: {:.2f}, MF1-std: {:.2f}, AUC-mean: {:.2f}, AUC-std: {:.2f}'.format(100 * np.mean(final_mf1s_s),\n",
    "                                                                                            100 * np.std(final_mf1s_s),\n",
    "                                                               100 * np.mean(final_aucs_s), 100 * np.std(final_aucs_s)))\n",
    "\n",
    "    final_mf1s_j = np.array(final_mf1s_j)\n",
    "    final_aucs_j = np.array(final_aucs_j)\n",
    "    # np.std :计算全局标准差\n",
    "    print('MF1-mean_j: {:.2f}, MF1-std: {:.2f}, AUC-mean: {:.2f}, AUC-std: {:.2f}'.format(100 * np.mean(final_mf1s_j),\n",
    "                                                                                            100 * np.std(final_mf1s_j),\n",
    "                                                               100 * np.mean(final_aucs_j), 100 * np.std(final_aucs_j)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6fd823-3979-4e4e-9d40-0bc5117dbbb3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
